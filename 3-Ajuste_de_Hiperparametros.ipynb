{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ajuste de Hiperparametros",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc-autonumbering": true,
    "toc-showcode": false,
    "toc-showmarkdowntxt": true
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmenesesrivera/codonusagebias/blob/main/3-Ajuste_de_Hiperparametros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SuL1f5NusVv"
      },
      "source": [
        "#Ajuste de Hiperparametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy1JTG6GuvPk"
      },
      "source": [
        "##Lectura de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi-rV2D-uWXE"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile, urllib.request, shutil\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00577/codon_usage.csv.zip'\n",
        "filename = 'codon_usage.csv.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLqSEywOLFOu"
      },
      "source": [
        "with urllib.request.urlopen(url) as response, open(filename, 'wb') as out_file:\n",
        "    shutil.copyfileobj(response, out_file)\n",
        "    with zipfile.ZipFile(filename) as zf:\n",
        "        zf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ftfn_cALFOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197ad27d-0391-44f6-b215-2daec58fb77f"
      },
      "source": [
        "!unzip codon_usage.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  codon_usage.csv\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "Archive:  codon_usage.csv.zip\n",
            "replace codon_usage.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: codon_usage.csv         \n",
            "replace __MACOSX/._codon_usage.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._codon_usage.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4nxU8-1u1No"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "labelencoder = LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M_o1ATdaD5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7f648f-2d73-4d85-b2a4-a3f808073580"
      },
      "source": [
        "#Lectura del dataset\n",
        "file_name = \"codon_usage.csv\"\n",
        "dataset =  pd.read_csv('https://drive.google.com/uc?export=download&id=1Z4v43cvTwp920NyOdboDKP7_ytC_0tBC')\n",
        "\n",
        "# Se observa que hay datos str que no permiten manipular los demás como numéricos.\n",
        "dataset[['UUU', 'UUC']] = dataset[['UUU', 'UUC']].apply(pd.to_numeric, errors='coerce')\n",
        "null_UUU = dataset['UUU'].isna().sum()\n",
        "null_UUC= dataset['UUC'].isna().sum()\n",
        "print (\"Cantidad de datos nulos en codon UUU \",null_UUU)\n",
        "print (\"Cantidad de datos nuls en codon UUC \",null_UUC)\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad de datos nulos en codon UUU  2\n",
            "Cantidad de datos nuls en codon UUC  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nThpxs7xaDlF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSoOAtn4QiVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c3bac9-6410-40b5-bc0a-b04e596ce6bd"
      },
      "source": [
        "dataset.describe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of 0      Kingdom  DNAtype  SpeciesID  ...      UAA      UAG      UGA\n",
              "0      Kingdom  DNAtype  SpeciesID  ...      UAA      UAG      UGA\n",
              "1          vrl        0     100217  ...  0.00251    5e-04        0\n",
              "2          vrl        0     100220  ...  0.00271  0.00068        0\n",
              "3          vrl        0     100755  ...  0.00391        0  0.00144\n",
              "4          vrl        0     100880  ...  0.00261  0.00157        0\n",
              "...        ...      ...        ...  ...      ...      ...      ...\n",
              "13024      pri        0       9601  ...  0.00091  0.00091  0.00638\n",
              "13025      pri        1       9601  ...  0.00242  0.00097  0.01887\n",
              "13026      pri        1       9602  ...  0.00356  0.00119  0.02017\n",
              "13027      pri        0       9606  ...  0.00099  0.00079  0.00156\n",
              "13028      pri        1       9606  ...  0.00156  0.00114  0.02161\n",
              "\n",
              "[13029 rows x 69 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ8wvu8sLFOy"
      },
      "source": [
        "def preprocess_dataset(dataset, save_metadata=True):\n",
        "  \n",
        "  preprocessed_dataset = dataset.copy()\n",
        "\n",
        "  #Determinamos aquellas variables que tengan un porcentaje de registros únicos por cada variable mayor al valor de 0.7\n",
        "  threshold = 0.7\n",
        "\n",
        "  unique_percentages = dataset.nunique() / len(dataset)\n",
        "\n",
        "  criteria = unique_percentages > threshold\n",
        "\n",
        "  columns_to_filter = unique_percentages[criteria].keys()\n",
        "  \n",
        "  # Está columna contiene datos descriptivos, por tanto será transformada a str.\n",
        "\n",
        "  preprocessed_dataset['SpeciesName'] = preprocessed_dataset['SpeciesName'].astype(str)\n",
        "  preprocessed_dataset['SpeciesName']\n",
        " \n",
        "  #Eliminamos las variables seleccionadas en el paso anterior\n",
        "  preprocessed_dataset.drop(columns_to_filter, axis=1, inplace=True)\n",
        " \n",
        "  #Eliminamos los registros duplicados\n",
        "  preprocessed_dataset.drop_duplicates(keep=\"first\", inplace=True)\n",
        "\n",
        "  #Determinamos que variables son del tipo númerico y cuales son categóricas\n",
        "  numeric_columns = list()\n",
        "  categorical_columns = list()\n",
        "  dictionary_of_columns_with_index_to_categorical = dict()\n",
        "  dictionary_of_columns_with_categorical_to_index = dict()\n",
        "\n",
        "  for column in preprocessed_dataset:\n",
        "    #Determinamos si la variable es numérica o no\n",
        "    if pd.api.types.is_numeric_dtype(preprocessed_dataset[column]):\n",
        "      numeric_columns.append(column)\n",
        "    else:\n",
        "      #Modificamos el tipo de dato de la variable mediante \"astype\"\n",
        "      preprocessed_dataset[column] = preprocessed_dataset[column].astype(\"category\")\n",
        "\n",
        "      #Verificamos si el tipo de dato de la variable fue transformado a categórico correctamente\n",
        "      if not pd.api.types.is_categorical_dtype(preprocessed_dataset[column]):\n",
        "        raise Exception(\"La columna {} no se transformó correctamente a categórica\".format(column))\n",
        "\n",
        "      dictionary_of_columns_with_index_to_categorical[column] = dict()\n",
        "      dictionary_of_columns_with_categorical_to_index[column] = dict()\n",
        "      \n",
        "      #Indexamos los valores (categorías), sin tomar en consideración los nulos, de la variable y guardamos esa información en los diccionarios\n",
        "      for index, category in enumerate(preprocessed_dataset[column].cat.categories):\n",
        "        dictionary_of_columns_with_index_to_categorical[column][index] = category\n",
        "        dictionary_of_columns_with_categorical_to_index[column][category] = index\n",
        "      \n",
        "      categorical_columns.append(column)\n",
        "  \n",
        "  #Reemplazamos los nulos con la mediana sólo de aquellas variables numéricas\n",
        "    median_of_numeric_columns = preprocessed_dataset[numeric_columns].median()\n",
        "    preprocessed_dataset[numeric_columns] = preprocessed_dataset[numeric_columns].fillna(median_of_numeric_columns)\n",
        "\n",
        "  #Transformamos a números los valores (categorías) de las variables categóricas sin considerar los nulos\n",
        "  preprocessed_dataset.replace(dictionary_of_columns_with_categorical_to_index, inplace=True)\n",
        "\n",
        "  #Determinamos aquellas variables que tengan un porcentaje de registros nulos por cada variable mayor al valor de 0.7\n",
        "  threshold = 0.7\n",
        "\n",
        "  null_percentages = preprocessed_dataset[categorical_columns].isna().sum() / len(preprocessed_dataset)\n",
        "\n",
        "  criteria = null_percentages > threshold\n",
        "\n",
        "  columns_to_filter = null_percentages[criteria].keys()\n",
        "\n",
        "  #Eliminamos las variables seleccionadas en el paso anterior\n",
        "  preprocessed_dataset.drop(columns_to_filter, axis=1, inplace=True)\n",
        "\n",
        "  #Eliminamos los registros duplicados\n",
        "  preprocessed_dataset.drop_duplicates(keep=\"first\", inplace=True)\n",
        " \n",
        "  return preprocessed_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0omGurMu-gl"
      },
      "source": [
        "preprocessed_dataset = preprocess_dataset(dataset)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCUQDNBRT8xG"
      },
      "source": [
        "X1 = preprocessed_dataset.drop(\"Kingdom\", axis=1)\n",
        "X2 = preprocessed_dataset.drop(\"DNAtype\", axis=1)\n",
        "Y1 = preprocessed_dataset[\"Kingdom\"]  \n",
        "Y2 = preprocessed_dataset[\"DNAtype\"] "
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB-IphpOLFO1"
      },
      "source": [
        "#Mediante el método \"train_test_split\" usaremos el 20% de la data para probar el modelo. El parámetro \"random state\" nos sirve para\n",
        "#poder replicar la misma separación\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(X1, Y1, test_size=0.2, random_state=70)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kldz2M2MAiY"
      },
      "source": [
        "#Mediante el método \"train_test_split\" usaremos el 20% de la data para probar el modelo. El parámetro \"random state\" nos sirve para\n",
        "#poder replicar la misma separación\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(X2, Y2, test_size=0.2, random_state=70)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbEbNLOdvhYF"
      },
      "source": [
        "##Eliminas algunas caracteristicas \n",
        "Basandonos en el colab anterior decidimos usar solo 5 de las caracteristicas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0ARmOifvwIf"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ac1ggXAv2s5",
        "outputId": "2ae659da-c3c8-4b91-bbed-e2c4d7ebb0e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "filtrado = SelectKBest(mutual_info_classif, k=5).fit(X1, Y1)\n",
        "X_new = filtrado.transform(x1_train)\n",
        "X_new[:5]"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4247., 3000., 2830., 3652., 1432.],\n",
              "       [4263., 4322., 2221., 3183., 2905.],\n",
              "       [ 123.,  467., 1439.,  940.,  916.],\n",
              "       [3585., 5129., 1948., 3523., 2630.],\n",
              "       [ 151., 1115., 1498., 1610.,  482.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAd_t9bhwoW8",
        "outputId": "6f62f37a-83ee-410f-9e3f-df3f13b7e6ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Xt_new = filtrado.transform(x1_test )\n",
        "Xt_new[:5]"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 266.,  883., 1363., 1572.,  759.],\n",
              "       [3960., 3499., 2236., 3477., 1840.],\n",
              "       [3546., 3139., 1588., 1734., 1960.],\n",
              "       [4001., 4489., 2640., 3026., 2429.],\n",
              "       [4611., 3609., 2967., 3879., 3011.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFNTg-DCw9YS"
      },
      "source": [
        "##Entrenamos cada modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZdAfb16xIkk"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKvuMXuaxHzM"
      },
      "source": [
        "###Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmosBD4u1pRG"
      },
      "source": [
        "Decission Tree Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnRSOe0Dw8px",
        "outputId": "687316fc-a20e-4676-e795-2ef8ba7688aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_new, y1_train)\n",
        "print('Max Depth: ', dt.tree_.max_depth)\n",
        "print('Score: ',dt.score(Xt_new,y1_test))\n",
        "print('F1: ', f1_score(y1_test, dt.predict(Xt_new), average='weighted'))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Depth:  26\n",
            "Score:  0.6760292420161601\n",
            "F1:  0.6769358937906165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTvGL-wq1r8D"
      },
      "source": [
        "Busqueda por Grilla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrGQQbNgy8E4",
        "outputId": "6c3b09c0-e5b2-4be0-b6e5-f55ddaa2f61b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = {\"max_depth\": [10,11,12,13,14,15,16,17, None], \"max_features\": [3,4,5], \"min_samples_leaf\": [3,4,5,6,7], \"criterion\": [\"gini\", \"entropy\"]}\n",
        "tree = DecisionTreeClassifier()\n",
        "dt_cv = GridSearchCV(tree, params, cv=5)\n",
        "dt_cv.fit(X_new, y1_train)\n",
        "print(\"Mejores Parametros: {}\".format(dt_cv.best_params_))\n",
        "print(\"Mejor Score {}\".format(dt_cv.best_score_))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mejores Parametros: {'criterion': 'gini', 'max_depth': 10, 'max_features': 5, 'min_samples_leaf': 7}\n",
            "Mejor Score 0.7042534979012361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkVkMZTY1uUU"
      },
      "source": [
        "Reentrenamos como los parametros encontrados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rxajmxHz7rU",
        "outputId": "76c2f73d-ccec-45a6-f048-c346d91e1b93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dt_final = DecisionTreeClassifier(max_depth=11, max_features=5, min_samples_leaf=7, criterion='gini')\n",
        "dt_final.fit(X_new, y1_train)\n",
        "print('Score: ',dt_final.score(Xt_new,y1_test))\n",
        "print('F1: ', f1_score(y1_test, dt_final.predict(Xt_new), average='weighted'))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score:  0.7079646017699115\n",
            "F1:  0.6927558820382347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnzy23ak1O4r"
      },
      "source": [
        "###Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNwAZCEZ1k7i"
      },
      "source": [
        "Random Forest Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXhg-Yoe1UqV",
        "outputId": "513cb540-d5aa-4089-9c42-de18b96d77d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rt = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "rt.fit(X_new, y1_train)\n",
        "print('Score: ',dt.score(Xt_new,y1_test))\n",
        "print('F1: ', f1_score(y1_test, rt.predict(Xt_new), average='weighted'))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score:  0.6760292420161601\n",
            "F1:  0.7364526077184702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEJftAxa1ndn"
      },
      "source": [
        "Busqueda por Grilla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAG7QupY1j1C",
        "tags": [],
        "outputId": "886dd6c9-3c3c-43aa-db6e-69679ee692db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = {\"n_estimators\": [40,50,100,150,200], \"max_depth\": [10,11,12,13,14,15,16,17], \"max_features\": [3,4,5], \"min_samples_leaf\": [3,4,5,6,7]}\n",
        "forest = RandomForestClassifier(oob_score=True)\n",
        "rf_cv = GridSearchCV(forest, params, cv=5)\n",
        "rf_cv.fit(X_new, y1_train)\n",
        "print(\"Mejores Parametros: {}\".format(rf_cv.best_params_))\n",
        "print(\"Mejor Score {}\".format(rf_cv.best_score_))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mejores Parametros: {'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 3, 'n_estimators': 40}\n",
            "Mejor Score 0.7440845505330588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Q3uf7GFdpC",
        "outputId": "6873682e-9512-4998-a477-252300931113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rf_final = RandomForestClassifier(oob_score=True, max_depth=16, max_features=4, min_samples_leaf=3, n_estimators=150)\n",
        "rf_final.fit(X_new, y1_train)\n",
        "print('Score: ',rf_final.score(Xt_new,y1_test))\n",
        "print('F1: ', f1_score(y1_test, rf_final.predict(Xt_new), average='weighted'))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score:  0.749134282416314\n",
            "F1:  0.7324586841528481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1jr2p4rAWP1"
      },
      "source": [
        "###KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amtZgRvTG79p"
      },
      "source": [
        "KNN BASE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAx08rhOAeVt",
        "outputId": "649cb47b-7d20-44bf-a537-c01030eb72e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "knn = KNeighborsClassifier(4)\n",
        "knn.fit(X_new, y1_train)\n",
        "print('Score: ',knn.score(Xt_new,y1_test))\n",
        "print('F1: ', f1_score(y1_test, knn.predict(Xt_new), average='weighted'))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score:  0.7222008464794152\n",
            "F1:  0.7131797116942324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYH_dz2aILt7",
        "outputId": "5121668b-689e-454e-b111-ff5c1b59a911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = {\"n_neighbors\": [3,4,5, 6,8,10], \"weights\": ['uniform', 'distance'], \"metric\": ['euclidean', 'manhattan']}\n",
        "forest = KNeighborsClassifier()\n",
        "knn_cv = GridSearchCV(forest, params, cv=5)\n",
        "knn_cv.fit(X_new, y1_train)\n",
        "print(\"Mejores Parametros: {}\".format(knn_cv.best_params_))\n",
        "print(\"Mejor Score {}\".format(knn_cv.best_score_))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mejores Parametros: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Mejor Score 0.7170496384163372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7udlSVwK0_B",
        "outputId": "af1eab17-48f1-4221-8612-9fc8515055c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "knn_final = KNeighborsClassifier(n_neighbors=4, metric='euclidean',weights='distance')\n",
        "knn_final.fit(X_new, y1_train)\n",
        "print('Score: ',knn_final.score(Xt_new,y1_test))\n",
        "print('F1: ', f1_score(y1_test, knn_final.predict(Xt_new), average='weighted'))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score:  0.7345132743362832\n",
            "F1:  0.7259008097900985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4NBCA4iMf90"
      },
      "source": [
        "###XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LhGiLlIMp0g"
      },
      "source": [
        "#### Y1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "494EVhB7MpgD",
        "outputId": "2009d585-5afe-4ca4-bf02-6e3abf44512f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Requiere de 65 características según la selección de características \n",
        "param_grid = {\n",
        " 'max_depth':range(9,10),\n",
        " 'subsample': [0.7,0.9]\n",
        "}\n",
        "\n",
        "xgb_Model = XGBClassifier(learning_rate=0.1, n_estimators=80, min_child_weight=1, subsample= 0.7, nthread=-1, n_jobs=-1,scoring='f1')\n",
        "\n",
        "xgb_Grid = GridSearchCV (estimator= xgb_Model, param_grid = param_grid )\n",
        "xgb_Grid.fit(x1_train,y1_train)\n",
        "\n",
        "print (\"optimal max_depth\",xgb_Grid.best_estimator_.max_depth) \n",
        "print (\"optimal xgb_Grid.best_score_\",xgb_Grid.best_score_)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYGj7eshMtS4"
      },
      "source": [
        "xgb_Grid.score(x1_test, y1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YasZbd30MtsK"
      },
      "source": [
        "#### Y2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XiiNamILFO9"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Requiere de 65 características según la selección de características \n",
        "\n",
        "param_grid = {\n",
        " 'max_depth':range(9,10)\n",
        "}\n",
        "\n",
        "xgb_Model2 = XGBClassifier(learning_rate=0.01, n_estimators=80, min_child_weight=2, gamma=0, colsample_bytree=0.8, subsample= 0.7, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27, n_jobs=-1,scoring='roc_auc')\n",
        "xgb_Grid2 = GridSearchCV (estimator= xgb_Model2, param_grid = param_grid )\n",
        " \n",
        "xgb_Grid2.fit(x2_train,y2_train)\n",
        " \n",
        "print (\"optimal max_depth\",xgb_Grid2.best_estimator_.max_depth)\n",
        "print (\"optimal xgb_Grid2.best_score_\",xgb_Grid2.best_score_)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QJvolVUMtHf"
      },
      "source": [
        "xgb_Grid2.score(x2_test, y2_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq-5fjN5dAi-"
      },
      "source": [
        "### Ligth GBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDEZFJkwec3Q"
      },
      "source": [
        "import lightgbm as lgb "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GFsgWzpdGhb"
      },
      "source": [
        "#### Y1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2V7j0C_dK_5"
      },
      "source": [
        "#Declaración de parámetros para el modelo\n",
        "\n",
        "\n",
        "params = {'boosting_type': 'gbdt',\n",
        "          'max_depth' : 10,\n",
        "          'nthread': -1, \n",
        "          'max_bin': 512,\n",
        "          'subsample_for_bin': 200,\n",
        "          'subsample_freq': 1,\n",
        "          'min_split_gain': 0.5,\n",
        "          'min_child_weight': 2,\n",
        "          'min_child_samples': 6,\n",
        "          'scale_pos_weight': 1,\n",
        "          'num_class' : 1,\n",
        "          'metric' : 'binary_error'}\n",
        "\n",
        "#Declaración de parámetros para GridSearchv\n",
        "\n",
        "gridParams = {\n",
        "    'learning_rate': [0.1],\n",
        "    'n_estimators': [91],\n",
        "    'num_leaves': [19],\n",
        "    'objective' : ['binary'],\n",
        "    'random_state' : [30], \n",
        "    'colsample_bytree' : [0.65],\n",
        "    'subsample' : [1],\n",
        "    'reg_alpha' : [1],\n",
        "    'reg_lambda' : [1.2],\n",
        "    }\n",
        "\n",
        "#Requiere de 64 características según la selección de características \n",
        "\n",
        "#Declaración de Modelo\n",
        "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt',\n",
        "          objective = 'binary',\n",
        "          n_jobs = -1, \n",
        "          silent = True,\n",
        "          max_depth = params['max_depth'],\n",
        "          max_bin = params['max_bin'],\n",
        "          subsample_for_bin = params['subsample_for_bin'],\n",
        "          subsample_freq = params['subsample_freq'],\n",
        "          min_split_gain = params['min_split_gain'],\n",
        "          min_child_weight = params['min_child_weight'],\n",
        "          min_child_samples = params['min_child_samples'],\n",
        "          scale_pos_weight = params['scale_pos_weight'])\n",
        "\n",
        "mdl.get_params().keys()\n",
        "#Ejecuciòn de GridSearchv\n",
        "grid = GridSearchCV(mdl, gridParams,\n",
        "                    verbose=0,\n",
        "                    cv=4,\n",
        "                    n_jobs=-1)\n",
        "#Entrenamiento\n",
        "grid.fit(x1_train, y1_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4-EtZXGfT9l"
      },
      "source": [
        "#Scores\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)\n",
        "print(grid.score(x1_test, y1_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxqMUJNFdLe4"
      },
      "source": [
        "#### Y2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd88DsZhffzU"
      },
      "source": [
        "#Declaración de parámetros para el modelo\n",
        "params2 = {'boosting_type': 'gbdt',\n",
        "          'max_depth' : 6,\n",
        "          'objective': 'binary',\n",
        "          'nthread': -1,\n",
        "          'num_leaves': 64,\n",
        "          'learning_rate': 0.05,\n",
        "          'max_bin': 512,\n",
        "          'subsample_for_bin': 200,\n",
        "          'subsample': 1,\n",
        "          'subsample_freq': 1,\n",
        "          'colsample_bytree': 0.8,\n",
        "          'reg_alpha': 5,\n",
        "          'reg_lambda': 10,\n",
        "          'min_split_gain': 0.5,\n",
        "          'min_child_weight': 2,\n",
        "          'min_child_samples': 6,\n",
        "          'scale_pos_weight': 1,\n",
        "          'num_class' : 1,\n",
        "          'metric' : 'binary_error'}\n",
        "          \n",
        "#Declaración de parámetros para GridSearchv\n",
        "\n",
        "gridParams2 = {\n",
        "    'learning_rate': [0.1],\n",
        "    'n_estimators': [90],\n",
        "    'num_leaves': [16],\n",
        "    'boosting_type' : ['gbdt'],\n",
        "    'objective' : ['binary'],\n",
        "    'random_state' : [30],\n",
        "    'colsample_bytree' : [0.65],\n",
        "    'subsample' : [0.9],\n",
        "    'reg_alpha' : [1],\n",
        "    'reg_lambda' : [1],\n",
        "    'max_depth' : [8]\n",
        "    }\n",
        "\n",
        "#Requiere de 64 características según la selección de características \n",
        "\n",
        "#Declaración de Modelo\n",
        "mdl2 = lgb.LGBMClassifier(boosting_type= 'gbdt',\n",
        "          objective = 'binary',\n",
        "          n_jobs = -1, \n",
        "          silent = True,\n",
        "          max_depth = params2['max_depth'],\n",
        "          max_bin = params2['max_bin'],\n",
        "          subsample_for_bin = params2['subsample_for_bin'],\n",
        "          subsample = params2['subsample'],\n",
        "          subsample_freq = params2['subsample_freq'],\n",
        "          min_split_gain = params2['min_split_gain'],\n",
        "          min_child_weight = params2['min_child_weight'],\n",
        "          min_child_samples = params2['min_child_samples'],\n",
        "          scale_pos_weight = params2['scale_pos_weight'])\n",
        "\n",
        "mdl2.get_params().keys()\n",
        "\n",
        "#Ejecuciòn de GridSearchv\n",
        "grid2 = GridSearchCV(mdl2, gridParams2,\n",
        "                    verbose=0,\n",
        "                    cv=4,\n",
        "                    n_jobs=-1)\n",
        "\n",
        "#Entrenamiento\n",
        "grid2.fit(x2_train, y2_train)\n",
        "\n",
        "#Scores\n",
        "print(grid2.best_params_)\n",
        "print(grid2.best_score_) \n",
        "print(grid2.score(x2_test, y2_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}