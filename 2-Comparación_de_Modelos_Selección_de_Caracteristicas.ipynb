{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparación de Modelos  - Selección de Caracteristicas",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmenesesrivera/codonusagebias/blob/main/2-Comparaci%C3%B3n_de_Modelos_Selecci%C3%B3n_de_Caracteristicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao5Xptodqtxp"
      },
      "source": [
        "##Comparación de Modelos  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TxYDgErqyHG"
      },
      "source": [
        "###Lectura de la Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PphHXFEffNrH"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile, urllib.request, shutil\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00577/codon_usage.csv.zip'\n",
        "filename = 'codon_usage.csv.zip'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-sYKioZfNrI"
      },
      "source": [
        "with urllib.request.urlopen(url) as response, open(filename, 'wb') as out_file:\n",
        "    shutil.copyfileobj(response, out_file)\n",
        "    with zipfile.ZipFile(filename) as zf:\n",
        "        zf.extractall()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvFBz9_ufNrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a6fdcd-3f1d-47a4-f804-9ed7ab4796d7"
      },
      "source": [
        "!unzip codon_usage.csv"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  codon_usage.csv\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "Archive:  codon_usage.csv.zip\n",
            "replace codon_usage.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttXoBVYCrPGR",
        "tags": []
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow.python.keras, math\n",
        "from sklearn.model_selection import train_test_split\n",
        "labelencoder = LabelEncoder()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nXffYItfNrL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "019912b6-43d2-4a7b-e2cf-21cb69cad0f6"
      },
      "source": [
        "#Lectura del dataset\n",
        "file_name = \"codon_usage.csv\"\n",
        "dataset = pd.read_csv(file_name,  header=None)\n",
        "# Eliminando columnas inválidas\n",
        "columns = dataset.iloc[0]\n",
        "dataset.columns = columns\n",
        "dataset = dataset.drop([0],axis=0)\n",
        "\n",
        "cols = dataset.columns[dataset.dtypes.eq(object)] # Seleccionamos las columnas con el tipo de datao : Object\n",
        "dataset = dataset[cols].apply(pd.to_numeric, errors='ignore') #se transforma\n",
        "\n",
        "# Se observa que hay datos str que no permiten manipular los demás como numéricos, por lo tanto se va a forzar.\n",
        "dataset[['UUU', 'UUC']] = dataset[['UUU', 'UUC']].apply(pd.to_numeric, errors='coerce')\n",
        "null_percentages = dataset['UUU'].isna().sum()\n",
        "null_percentages\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d4ccb766bdf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Lectura del dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"codon_usage.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Eliminando columnas inválidas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'codon_usage.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qhbTi-KfNrM"
      },
      "source": [
        "def preprocess_dataset(dataset, save_metadata=True):\n",
        "  \n",
        "  preprocessed_dataset = dataset.copy()\n",
        "\n",
        "  #Determinamos aquellas variables que tengan un porcentaje de registros únicos por cada variable mayor al valor de 0.7\n",
        "  threshold = 0.7\n",
        "\n",
        "  unique_percentages = dataset.nunique() / len(dataset)\n",
        "\n",
        "  criteria = unique_percentages > threshold\n",
        "\n",
        "  columns_to_filter = unique_percentages[criteria].keys()\n",
        "  \n",
        "  # Está columna contiene datos descriptivos, por tanto será transformada a str.\n",
        "\n",
        "  preprocessed_dataset['SpeciesName'] = preprocessed_dataset['SpeciesName'].astype(str)\n",
        "  preprocessed_dataset['SpeciesName']\n",
        " \n",
        "  #Eliminamos las variables seleccionadas en el paso anterior\n",
        "  preprocessed_dataset.drop(columns_to_filter, axis=1, inplace=True)\n",
        " \n",
        "  #Eliminamos los registros duplicados\n",
        "  preprocessed_dataset.drop_duplicates(keep=\"first\", inplace=True)\n",
        "\n",
        "  #Determinamos que variables son del tipo númerico y cuales son categóricas\n",
        "  numeric_columns = list()\n",
        "  categorical_columns = list()\n",
        "  dictionary_of_columns_with_index_to_categorical = dict()\n",
        "  dictionary_of_columns_with_categorical_to_index = dict()\n",
        "\n",
        "  for column in preprocessed_dataset:\n",
        "    #Determinamos si la variable es numérica o no\n",
        "    if pd.api.types.is_numeric_dtype(preprocessed_dataset[column]):\n",
        "      numeric_columns.append(column)\n",
        "    else:\n",
        "      #Modificamos el tipo de dato de la variable mediante \"astype\"\n",
        "      preprocessed_dataset[column] = preprocessed_dataset[column].astype(\"category\")\n",
        "\n",
        "      #Verificamos si el tipo de dato de la variable fue transformado a categórico correctamente\n",
        "      if not pd.api.types.is_categorical_dtype(preprocessed_dataset[column]):\n",
        "        raise Exception(\"La columna {} no se transformó correctamente a categórica\".format(column))\n",
        "\n",
        "      dictionary_of_columns_with_index_to_categorical[column] = dict()\n",
        "      dictionary_of_columns_with_categorical_to_index[column] = dict()\n",
        "      \n",
        "      #Indexamos los valores (categorías), sin tomar en consideración los nulos, de la variable y guardamos esa información en los diccionarios\n",
        "      for index, category in enumerate(preprocessed_dataset[column].cat.categories):\n",
        "        dictionary_of_columns_with_index_to_categorical[column][index] = category\n",
        "        dictionary_of_columns_with_categorical_to_index[column][category] = index\n",
        "      \n",
        "      categorical_columns.append(column)\n",
        "  \n",
        "  #Reemplazamos los nulos con la mediana sólo de aquellas variables numéricas\n",
        "    median_of_numeric_columns = preprocessed_dataset[numeric_columns].median()\n",
        "    preprocessed_dataset[numeric_columns] = preprocessed_dataset[numeric_columns].fillna(median_of_numeric_columns)\n",
        "\n",
        "  #Transformamos a números los valores (categorías) de las variables categóricas sin considerar los nulos\n",
        "  preprocessed_dataset.replace(dictionary_of_columns_with_categorical_to_index, inplace=True)\n",
        "\n",
        "  #Determinamos aquellas variables que tengan un porcentaje de registros nulos por cada variable mayor al valor de 0.7\n",
        "  threshold = 0.7\n",
        "\n",
        "  null_percentages = preprocessed_dataset[categorical_columns].isna().sum() / len(preprocessed_dataset)\n",
        "\n",
        "  criteria = null_percentages > threshold\n",
        "\n",
        "  columns_to_filter = null_percentages[criteria].keys()\n",
        "\n",
        "  #Eliminamos las variables seleccionadas en el paso anterior\n",
        "  preprocessed_dataset.drop(columns_to_filter, axis=1, inplace=True)\n",
        "\n",
        "  #Eliminamos los registros duplicados\n",
        "  preprocessed_dataset.drop_duplicates(keep=\"first\", inplace=True)\n",
        " \n",
        "  return preprocessed_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5QCuYFYfNrN"
      },
      "source": [
        "preprocessed_dataset = preprocess_dataset(dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_wggFtPhbkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3b1b7a-525e-43d1-9700-3f5af86ec3e6"
      },
      "source": [
        "preprocessed_dataset.describe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of 0      Kingdom  DNAtype   Ncodons      UUU  ...      GAG      UAA      UAG      UGA\n",
              "1            9        0      1995  0.01654  ...  0.04361  0.00251  0.00050  0.00000\n",
              "2            9        0      1474  0.02714  ...  0.04410  0.00271  0.00068  0.00000\n",
              "3            9        0      4862  0.01974  ...  0.02468  0.00391  0.00000  0.00144\n",
              "4            9        0      1915  0.01775  ...  0.03446  0.00261  0.00157  0.00000\n",
              "5            9        0     22831  0.02816  ...  0.03679  0.00000  0.00044  0.00131\n",
              "...        ...      ...       ...      ...  ...      ...      ...      ...      ...\n",
              "13024        7        0      1097  0.02552  ...  0.04102  0.00091  0.00091  0.00638\n",
              "13025        7        1      2067  0.01258  ...  0.00677  0.00242  0.00097  0.01887\n",
              "13026        7        1      1686  0.01423  ...  0.00297  0.00356  0.00119  0.02017\n",
              "13027        7        0  40662582  0.01757  ...  0.03959  0.00099  0.00079  0.00156\n",
              "13028        7        1   8998998  0.01778  ...  0.00783  0.00156  0.00114  0.02161\n",
              "\n",
              "[12991 rows x 67 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVy-AIUjfNrP"
      },
      "source": [
        "#Separamos las columnas  Reino y ADN  , respectivamente.\n",
        "X1 = preprocessed_dataset.drop(\"Kingdom\", axis=1)\n",
        "X2 = preprocessed_dataset.drop(\"DNAtype\", axis=1)\n",
        "Y1 = preprocessed_dataset[\"Kingdom\"]  \n",
        "Y2 = preprocessed_dataset[\"DNAtype\"] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkSzfWZOfNrQ"
      },
      "source": [
        "#Mediante el método \"train_test_split\" usaremos el 20% de la data para probar el modelo. El parámetro \"random state\" nos sirve para\n",
        "#poder replicar la misma separación\n",
        "x_train, Xt, y_train, Yt = train_test_split(X1, Y1, test_size=0.2, random_state=70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bLFpoKEk_4q"
      },
      "source": [
        "#Mediante el método \"train_test_split\" usaremos el 20% de la data para probar el modelo. El parámetro \"random state\" nos sirve para\n",
        "#poder replicar la misma separación\n",
        "x2_train, Xt2, y2_train, Yt2 = train_test_split(X2, Y2, test_size=0.2, random_state=70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b558tq8I-1mU"
      },
      "source": [
        "Ahora vamos a probar los modelos sin tunearlos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POJRvjNhtbRF"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uExErJ5xkwzn"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mj8C8rYsi3w",
        "outputId": "cdcef903-acf7-45c9-ba15-bc50b5567955"
      },
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train, y_train) #Entrenamos un Decision Tree tunear"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwU3DHdutOKT",
        "outputId": "aeca0cc2-7925-4b99-ac05-c89518c4d5a6"
      },
      "source": [
        "f1_score(Yt, dt.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7714955449405004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnhb-9Xkkzty"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kTPg8pnkzNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563d104d-35ba-4995-9e64-5bc473778e47"
      },
      "source": [
        "dt2 = DecisionTreeClassifier()\n",
        "dt2.fit(x2_train, y2_train) #Entrenamos un Decision Tree tunear"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdyMBoG2ky3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa6e1a9-8920-424e-a7f3-7cb4fe30ce68"
      },
      "source": [
        "f1_score(Yt2, dt2.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.974913794959661"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5R9WwtDtemd"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvoLca-almK0"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThNghRCdthLR",
        "outputId": "dd4b5d88-d97b-426f-f79a-a662ca310456"
      },
      "source": [
        "rf = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "rf.fit(x_train, y_train) #Entrenamos un Random Forest sin tunear"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
              "                       oob_score=True, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP8HcMKduOn2",
        "outputId": "3b4bf441-11f3-4b78-8285-af9ac1536643"
      },
      "source": [
        "f1_score(Yt, rf.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8747286125156047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1BOEAWIlnCa"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xTU_A55lp5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8084cb1f-d965-47d6-ae3d-a4f0563d4de3"
      },
      "source": [
        "rf2 = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "rf2.fit(x2_train, y2_train) #Entrenamos un Random Forest sin tunear"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
              "                       oob_score=True, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH-JtItbltBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bce59ad-c37a-42ca-de9d-e5be69be27c5"
      },
      "source": [
        "f1_score(Yt2, rf2.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9880422316034267"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Z8EBmBusht"
      },
      "source": [
        "##Clasificador K-Nearest Neighbor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWRFaGyMl02V"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8D9-CaXur1X",
        "outputId": "64994a43-eb94-4391-c802-67d5d6d961cf"
      },
      "source": [
        "n_neighbors = 4\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors)\n",
        "knn.fit(x_train, y_train) #Entrenamos un KNN sin tunear"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pxIn5Mwu3dp",
        "outputId": "bebddfd5-1d8f-4cb4-83f6-b8c516ba9b7f"
      },
      "source": [
        "f1_score(Yt, knn.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37425189253279567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAw4QUVAl15t"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRowqVZ8l3mB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbee945-b64f-49a7-d7e5-82fd130aee90"
      },
      "source": [
        "n_neighbors = 4\n",
        "\n",
        "knn2 = KNeighborsClassifier(n_neighbors)\n",
        "knn2.fit(x2_train, y2_train) #Entrenamos un KNN sin tunear"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmx32Eikl5d_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fa61a2-ee54-494e-d83e-3163e5a3875b"
      },
      "source": [
        "f1_score(Yt2, knn2.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7578392501379395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d97Ct07PiFMx"
      },
      "source": [
        "# Clasificador XGBost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN3PspfTmVUW"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltT6A_HmiFCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d997739e-7ea0-472a-ec84-03af63fcd900"
      },
      "source": [
        " xgb=XGBClassifier(n_estimators=80,  max_depth=10)\n",
        " xgb.fit(x_train, y_train) #Entrenamos un XGBost sin tunear\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
              "              min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC-i__LMiCbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9ebbe4-7d39-4c1b-8416-87ae1d5c2b9c"
      },
      "source": [
        "f1_score(Yt, xgb.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9017597020186107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAkpR_mBmX8S"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40OPwDB9mY8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6341067c-b001-41ce-bdc4-62bad359ef0f"
      },
      "source": [
        "xgb2=XGBClassifier(n_estimators=80, max_depth=10 )\n",
        "xgb2.fit(x2_train, y2_train) #Entrenamos un XGBost sin tunear\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
              "              min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZxJJnpmaso",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "73ab4ce5-ab14-4c2c-9051-3e0d07af9fcc"
      },
      "source": [
        "f1_score(Yt2, xgb.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-242-0a8383c9d5f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Usamos F1 para comparar con otros modelos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                                                  validate_features=validate_features)\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1690\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['DNAtype', 'Ncodons', 'UUU', 'UUC', 'UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG', 'AUU', 'AUC', 'AUA', 'AUG', 'GUU', 'GUC', 'GUA', 'GUG', 'GCU', 'GCC', 'GCA', 'GCG', 'CCU', 'CCC', 'CCA', 'CCG', 'UGG', 'GGU', 'GGC', 'GGA', 'GGG', 'UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC', 'ACU', 'ACC', 'ACA', 'ACG', 'UAU', 'UAC', 'CAA', 'CAG', 'AAU', 'AAC', 'UGU', 'UGC', 'CAU', 'CAC', 'AAA', 'AAG', 'CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'GAU', 'GAC', 'GAA', 'GAG', 'UAA', 'UAG', 'UGA'] ['Kingdom', 'Ncodons', 'UUU', 'UUC', 'UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG', 'AUU', 'AUC', 'AUA', 'AUG', 'GUU', 'GUC', 'GUA', 'GUG', 'GCU', 'GCC', 'GCA', 'GCG', 'CCU', 'CCC', 'CCA', 'CCG', 'UGG', 'GGU', 'GGC', 'GGA', 'GGG', 'UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC', 'ACU', 'ACC', 'ACA', 'ACG', 'UAU', 'UAC', 'CAA', 'CAG', 'AAU', 'AAC', 'UGU', 'UGC', 'CAU', 'CAC', 'AAA', 'AAG', 'CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'GAU', 'GAC', 'GAA', 'GAG', 'UAA', 'UAG', 'UGA']\nexpected DNAtype in input data\ntraining data did not have the following fields: Kingdom"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4GmEyFGi9td"
      },
      "source": [
        "# Clasificador LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNx0kxemp1Xr"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZVOWCKwjAZi"
      },
      "source": [
        "mdl = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "mdl.fit(x_train, y_train) #Entrenamos un LightGBM sin tunear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lXfZzOGkHjW"
      },
      "source": [
        "f1_score(Yt, mdl.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnGfMZnlpzo_"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FyDcK1CpzHU"
      },
      "source": [
        "mdl2 = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',max_depth = 10)\n",
        "mdl2.fit(x2_train, y2_train) #Entrenamos un XGBost sin tunear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdhITx5WpyyP"
      },
      "source": [
        "f1_score(Yt2, mdl2.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXjmRsBpyACd"
      },
      "source": [
        "# Redes neuronales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6knijcgew4L1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "d6e51beb-2b00-4bbb-99ad-b980aac77df4"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, MultiLabelBinarizer\n",
        "import tensorflow as tf\n",
        "dataset = pd.read_csv('https://drive.google.com/uc?export=download&id=1Z4v43cvTwp920NyOdboDKP7_ytC_0tBC')\n",
        "dataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kingdom</th>\n",
              "      <th>DNAtype</th>\n",
              "      <th>SpeciesID</th>\n",
              "      <th>Ncodons</th>\n",
              "      <th>SpeciesName</th>\n",
              "      <th>UUU</th>\n",
              "      <th>UUC</th>\n",
              "      <th>UUA</th>\n",
              "      <th>UUG</th>\n",
              "      <th>CUU</th>\n",
              "      <th>CUC</th>\n",
              "      <th>CUA</th>\n",
              "      <th>CUG</th>\n",
              "      <th>AUU</th>\n",
              "      <th>AUC</th>\n",
              "      <th>AUA</th>\n",
              "      <th>AUG</th>\n",
              "      <th>GUU</th>\n",
              "      <th>GUC</th>\n",
              "      <th>GUA</th>\n",
              "      <th>GUG</th>\n",
              "      <th>GCU</th>\n",
              "      <th>GCC</th>\n",
              "      <th>GCA</th>\n",
              "      <th>GCG</th>\n",
              "      <th>CCU</th>\n",
              "      <th>CCC</th>\n",
              "      <th>CCA</th>\n",
              "      <th>CCG</th>\n",
              "      <th>UGG</th>\n",
              "      <th>GGU</th>\n",
              "      <th>GGC</th>\n",
              "      <th>GGA</th>\n",
              "      <th>GGG</th>\n",
              "      <th>UCU</th>\n",
              "      <th>UCC</th>\n",
              "      <th>UCA</th>\n",
              "      <th>UCG</th>\n",
              "      <th>AGU</th>\n",
              "      <th>AGC</th>\n",
              "      <th>ACU</th>\n",
              "      <th>ACC</th>\n",
              "      <th>ACA</th>\n",
              "      <th>ACG</th>\n",
              "      <th>UAU</th>\n",
              "      <th>UAC</th>\n",
              "      <th>CAA</th>\n",
              "      <th>CAG</th>\n",
              "      <th>AAU</th>\n",
              "      <th>AAC</th>\n",
              "      <th>UGU</th>\n",
              "      <th>UGC</th>\n",
              "      <th>CAU</th>\n",
              "      <th>CAC</th>\n",
              "      <th>AAA</th>\n",
              "      <th>AAG</th>\n",
              "      <th>CGU</th>\n",
              "      <th>CGC</th>\n",
              "      <th>CGA</th>\n",
              "      <th>CGG</th>\n",
              "      <th>AGA</th>\n",
              "      <th>AGG</th>\n",
              "      <th>GAU</th>\n",
              "      <th>GAC</th>\n",
              "      <th>GAA</th>\n",
              "      <th>GAG</th>\n",
              "      <th>UAA</th>\n",
              "      <th>UAG</th>\n",
              "      <th>UGA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vrl</td>\n",
              "      <td>0</td>\n",
              "      <td>100217</td>\n",
              "      <td>1995</td>\n",
              "      <td>Epizootic haematopoietic necrosis virus</td>\n",
              "      <td>0.01654</td>\n",
              "      <td>0.01203</td>\n",
              "      <td>0.00050</td>\n",
              "      <td>0.00351</td>\n",
              "      <td>0.01203</td>\n",
              "      <td>0.03208</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>0.04010</td>\n",
              "      <td>0.00551</td>\n",
              "      <td>0.02005</td>\n",
              "      <td>0.00752</td>\n",
              "      <td>0.02506</td>\n",
              "      <td>0.01103</td>\n",
              "      <td>0.04110</td>\n",
              "      <td>0.00902</td>\n",
              "      <td>0.03308</td>\n",
              "      <td>0.01003</td>\n",
              "      <td>0.05013</td>\n",
              "      <td>0.01554</td>\n",
              "      <td>0.01103</td>\n",
              "      <td>0.02356</td>\n",
              "      <td>0.03208</td>\n",
              "      <td>0.01203</td>\n",
              "      <td>0.00501</td>\n",
              "      <td>0.01003</td>\n",
              "      <td>0.01203</td>\n",
              "      <td>0.03158</td>\n",
              "      <td>0.01905</td>\n",
              "      <td>0.02456</td>\n",
              "      <td>0.01353</td>\n",
              "      <td>0.02155</td>\n",
              "      <td>0.00251</td>\n",
              "      <td>0.00652</td>\n",
              "      <td>0.00150</td>\n",
              "      <td>0.01554</td>\n",
              "      <td>0.00501</td>\n",
              "      <td>0.02105</td>\n",
              "      <td>0.00902</td>\n",
              "      <td>0.01053</td>\n",
              "      <td>0.00501</td>\n",
              "      <td>0.02256</td>\n",
              "      <td>0.00301</td>\n",
              "      <td>0.03108</td>\n",
              "      <td>0.00401</td>\n",
              "      <td>0.02607</td>\n",
              "      <td>0.00251</td>\n",
              "      <td>0.01153</td>\n",
              "      <td>0.00501</td>\n",
              "      <td>0.02356</td>\n",
              "      <td>0.01053</td>\n",
              "      <td>0.03860</td>\n",
              "      <td>0.00401</td>\n",
              "      <td>0.00702</td>\n",
              "      <td>0.00401</td>\n",
              "      <td>0.00451</td>\n",
              "      <td>0.01303</td>\n",
              "      <td>0.03559</td>\n",
              "      <td>0.01003</td>\n",
              "      <td>0.04612</td>\n",
              "      <td>0.01203</td>\n",
              "      <td>0.04361</td>\n",
              "      <td>0.00251</td>\n",
              "      <td>0.00050</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vrl</td>\n",
              "      <td>0</td>\n",
              "      <td>100220</td>\n",
              "      <td>1474</td>\n",
              "      <td>Bohle iridovirus</td>\n",
              "      <td>0.02714</td>\n",
              "      <td>0.01357</td>\n",
              "      <td>0.00068</td>\n",
              "      <td>0.00678</td>\n",
              "      <td>0.00407</td>\n",
              "      <td>0.02849</td>\n",
              "      <td>0.00204</td>\n",
              "      <td>0.04410</td>\n",
              "      <td>0.01153</td>\n",
              "      <td>0.02510</td>\n",
              "      <td>0.00882</td>\n",
              "      <td>0.03324</td>\n",
              "      <td>0.00814</td>\n",
              "      <td>0.04071</td>\n",
              "      <td>0.00814</td>\n",
              "      <td>0.03256</td>\n",
              "      <td>0.01085</td>\n",
              "      <td>0.04885</td>\n",
              "      <td>0.01221</td>\n",
              "      <td>0.01357</td>\n",
              "      <td>0.00678</td>\n",
              "      <td>0.02714</td>\n",
              "      <td>0.01221</td>\n",
              "      <td>0.00407</td>\n",
              "      <td>0.01425</td>\n",
              "      <td>0.01221</td>\n",
              "      <td>0.01967</td>\n",
              "      <td>0.02239</td>\n",
              "      <td>0.01289</td>\n",
              "      <td>0.02103</td>\n",
              "      <td>0.01493</td>\n",
              "      <td>0.00407</td>\n",
              "      <td>0.00475</td>\n",
              "      <td>0.00068</td>\n",
              "      <td>0.02035</td>\n",
              "      <td>0.00950</td>\n",
              "      <td>0.02782</td>\n",
              "      <td>0.01425</td>\n",
              "      <td>0.00611</td>\n",
              "      <td>0.00475</td>\n",
              "      <td>0.02917</td>\n",
              "      <td>0.00407</td>\n",
              "      <td>0.02374</td>\n",
              "      <td>0.00882</td>\n",
              "      <td>0.02917</td>\n",
              "      <td>0.00271</td>\n",
              "      <td>0.01628</td>\n",
              "      <td>0.00204</td>\n",
              "      <td>0.01967</td>\n",
              "      <td>0.00543</td>\n",
              "      <td>0.03392</td>\n",
              "      <td>0.00136</td>\n",
              "      <td>0.00678</td>\n",
              "      <td>0.00136</td>\n",
              "      <td>0.00136</td>\n",
              "      <td>0.01696</td>\n",
              "      <td>0.03596</td>\n",
              "      <td>0.01221</td>\n",
              "      <td>0.04545</td>\n",
              "      <td>0.01560</td>\n",
              "      <td>0.04410</td>\n",
              "      <td>0.00271</td>\n",
              "      <td>0.00068</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vrl</td>\n",
              "      <td>0</td>\n",
              "      <td>100755</td>\n",
              "      <td>4862</td>\n",
              "      <td>Sweet potato leaf curl virus</td>\n",
              "      <td>0.01974</td>\n",
              "      <td>0.0218</td>\n",
              "      <td>0.01357</td>\n",
              "      <td>0.01543</td>\n",
              "      <td>0.00782</td>\n",
              "      <td>0.01111</td>\n",
              "      <td>0.01028</td>\n",
              "      <td>0.01193</td>\n",
              "      <td>0.02283</td>\n",
              "      <td>0.01604</td>\n",
              "      <td>0.01316</td>\n",
              "      <td>0.02180</td>\n",
              "      <td>0.01625</td>\n",
              "      <td>0.01872</td>\n",
              "      <td>0.01213</td>\n",
              "      <td>0.01070</td>\n",
              "      <td>0.02406</td>\n",
              "      <td>0.01234</td>\n",
              "      <td>0.01440</td>\n",
              "      <td>0.00514</td>\n",
              "      <td>0.01604</td>\n",
              "      <td>0.01460</td>\n",
              "      <td>0.02098</td>\n",
              "      <td>0.01070</td>\n",
              "      <td>0.01728</td>\n",
              "      <td>0.01851</td>\n",
              "      <td>0.00864</td>\n",
              "      <td>0.01172</td>\n",
              "      <td>0.01892</td>\n",
              "      <td>0.01933</td>\n",
              "      <td>0.01419</td>\n",
              "      <td>0.01296</td>\n",
              "      <td>0.00967</td>\n",
              "      <td>0.01337</td>\n",
              "      <td>0.01337</td>\n",
              "      <td>0.01851</td>\n",
              "      <td>0.01131</td>\n",
              "      <td>0.01419</td>\n",
              "      <td>0.01090</td>\n",
              "      <td>0.02612</td>\n",
              "      <td>0.01275</td>\n",
              "      <td>0.01522</td>\n",
              "      <td>0.02365</td>\n",
              "      <td>0.02962</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.01625</td>\n",
              "      <td>0.01234</td>\n",
              "      <td>0.01604</td>\n",
              "      <td>0.01687</td>\n",
              "      <td>0.02077</td>\n",
              "      <td>0.03949</td>\n",
              "      <td>0.00864</td>\n",
              "      <td>0.00596</td>\n",
              "      <td>0.00926</td>\n",
              "      <td>0.00596</td>\n",
              "      <td>0.01974</td>\n",
              "      <td>0.02489</td>\n",
              "      <td>0.03126</td>\n",
              "      <td>0.02036</td>\n",
              "      <td>0.02242</td>\n",
              "      <td>0.02468</td>\n",
              "      <td>0.00391</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vrl</td>\n",
              "      <td>0</td>\n",
              "      <td>100880</td>\n",
              "      <td>1915</td>\n",
              "      <td>Northern cereal mosaic virus</td>\n",
              "      <td>0.01775</td>\n",
              "      <td>0.02245</td>\n",
              "      <td>0.01619</td>\n",
              "      <td>0.00992</td>\n",
              "      <td>0.01567</td>\n",
              "      <td>0.01358</td>\n",
              "      <td>0.00940</td>\n",
              "      <td>0.01723</td>\n",
              "      <td>0.02402</td>\n",
              "      <td>0.02245</td>\n",
              "      <td>0.02507</td>\n",
              "      <td>0.02924</td>\n",
              "      <td>0.02089</td>\n",
              "      <td>0.02141</td>\n",
              "      <td>0.01723</td>\n",
              "      <td>0.01932</td>\n",
              "      <td>0.02141</td>\n",
              "      <td>0.00679</td>\n",
              "      <td>0.02245</td>\n",
              "      <td>0.00522</td>\n",
              "      <td>0.01358</td>\n",
              "      <td>0.00418</td>\n",
              "      <td>0.01410</td>\n",
              "      <td>0.00574</td>\n",
              "      <td>0.01201</td>\n",
              "      <td>0.00992</td>\n",
              "      <td>0.00366</td>\n",
              "      <td>0.02402</td>\n",
              "      <td>0.02663</td>\n",
              "      <td>0.02872</td>\n",
              "      <td>0.00992</td>\n",
              "      <td>0.02350</td>\n",
              "      <td>0.00522</td>\n",
              "      <td>0.01619</td>\n",
              "      <td>0.00836</td>\n",
              "      <td>0.02037</td>\n",
              "      <td>0.01358</td>\n",
              "      <td>0.02089</td>\n",
              "      <td>0.00731</td>\n",
              "      <td>0.02141</td>\n",
              "      <td>0.00888</td>\n",
              "      <td>0.01567</td>\n",
              "      <td>0.01253</td>\n",
              "      <td>0.02298</td>\n",
              "      <td>0.01358</td>\n",
              "      <td>0.00992</td>\n",
              "      <td>0.00888</td>\n",
              "      <td>0.00783</td>\n",
              "      <td>0.00679</td>\n",
              "      <td>0.03133</td>\n",
              "      <td>0.04282</td>\n",
              "      <td>0.00627</td>\n",
              "      <td>0.00261</td>\n",
              "      <td>0.00261</td>\n",
              "      <td>0.00366</td>\n",
              "      <td>0.01410</td>\n",
              "      <td>0.01671</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.01932</td>\n",
              "      <td>0.03029</td>\n",
              "      <td>0.03446</td>\n",
              "      <td>0.00261</td>\n",
              "      <td>0.00157</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vrl</td>\n",
              "      <td>0</td>\n",
              "      <td>100887</td>\n",
              "      <td>22831</td>\n",
              "      <td>Soil-borne cereal mosaic virus</td>\n",
              "      <td>0.02816</td>\n",
              "      <td>0.01371</td>\n",
              "      <td>0.00767</td>\n",
              "      <td>0.03679</td>\n",
              "      <td>0.01380</td>\n",
              "      <td>0.00548</td>\n",
              "      <td>0.00473</td>\n",
              "      <td>0.02076</td>\n",
              "      <td>0.02716</td>\n",
              "      <td>0.00867</td>\n",
              "      <td>0.01310</td>\n",
              "      <td>0.02773</td>\n",
              "      <td>0.02803</td>\n",
              "      <td>0.00508</td>\n",
              "      <td>0.00920</td>\n",
              "      <td>0.02965</td>\n",
              "      <td>0.02878</td>\n",
              "      <td>0.00574</td>\n",
              "      <td>0.01572</td>\n",
              "      <td>0.01577</td>\n",
              "      <td>0.01007</td>\n",
              "      <td>0.00508</td>\n",
              "      <td>0.00604</td>\n",
              "      <td>0.00679</td>\n",
              "      <td>0.01205</td>\n",
              "      <td>0.03127</td>\n",
              "      <td>0.00775</td>\n",
              "      <td>0.00959</td>\n",
              "      <td>0.00797</td>\n",
              "      <td>0.02006</td>\n",
              "      <td>0.00359</td>\n",
              "      <td>0.00933</td>\n",
              "      <td>0.01191</td>\n",
              "      <td>0.01616</td>\n",
              "      <td>0.00788</td>\n",
              "      <td>0.02593</td>\n",
              "      <td>0.00854</td>\n",
              "      <td>0.01200</td>\n",
              "      <td>0.02098</td>\n",
              "      <td>0.02089</td>\n",
              "      <td>0.01367</td>\n",
              "      <td>0.01502</td>\n",
              "      <td>0.01809</td>\n",
              "      <td>0.02738</td>\n",
              "      <td>0.01796</td>\n",
              "      <td>0.01082</td>\n",
              "      <td>0.00705</td>\n",
              "      <td>0.01174</td>\n",
              "      <td>0.00858</td>\n",
              "      <td>0.03408</td>\n",
              "      <td>0.03964</td>\n",
              "      <td>0.00950</td>\n",
              "      <td>0.00429</td>\n",
              "      <td>0.00578</td>\n",
              "      <td>0.00604</td>\n",
              "      <td>0.01494</td>\n",
              "      <td>0.01734</td>\n",
              "      <td>0.04148</td>\n",
              "      <td>0.02483</td>\n",
              "      <td>0.03359</td>\n",
              "      <td>0.03679</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00044</td>\n",
              "      <td>0.00131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13023</th>\n",
              "      <td>pri</td>\n",
              "      <td>0</td>\n",
              "      <td>9601</td>\n",
              "      <td>1097</td>\n",
              "      <td>Pongo pygmaeus abelii</td>\n",
              "      <td>0.02552</td>\n",
              "      <td>0.03555</td>\n",
              "      <td>0.00547</td>\n",
              "      <td>0.01367</td>\n",
              "      <td>0.01276</td>\n",
              "      <td>0.02097</td>\n",
              "      <td>0.00820</td>\n",
              "      <td>0.03555</td>\n",
              "      <td>0.01459</td>\n",
              "      <td>0.03920</td>\n",
              "      <td>0.01003</td>\n",
              "      <td>0.02097</td>\n",
              "      <td>0.00912</td>\n",
              "      <td>0.02005</td>\n",
              "      <td>0.01003</td>\n",
              "      <td>0.03737</td>\n",
              "      <td>0.02279</td>\n",
              "      <td>0.01367</td>\n",
              "      <td>0.01094</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.01641</td>\n",
              "      <td>0.01094</td>\n",
              "      <td>0.01185</td>\n",
              "      <td>0.00182</td>\n",
              "      <td>0.01094</td>\n",
              "      <td>0.00456</td>\n",
              "      <td>0.01276</td>\n",
              "      <td>0.01094</td>\n",
              "      <td>0.01276</td>\n",
              "      <td>0.02097</td>\n",
              "      <td>0.01003</td>\n",
              "      <td>0.01003</td>\n",
              "      <td>0.00091</td>\n",
              "      <td>0.01732</td>\n",
              "      <td>0.01459</td>\n",
              "      <td>0.01276</td>\n",
              "      <td>0.01276</td>\n",
              "      <td>0.01641</td>\n",
              "      <td>0.00820</td>\n",
              "      <td>0.02370</td>\n",
              "      <td>0.02097</td>\n",
              "      <td>0.02917</td>\n",
              "      <td>0.03464</td>\n",
              "      <td>0.02005</td>\n",
              "      <td>0.02005</td>\n",
              "      <td>0.01459</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.01367</td>\n",
              "      <td>0.01459</td>\n",
              "      <td>0.01914</td>\n",
              "      <td>0.03008</td>\n",
              "      <td>0.00182</td>\n",
              "      <td>0.00547</td>\n",
              "      <td>0.00547</td>\n",
              "      <td>0.00820</td>\n",
              "      <td>0.01367</td>\n",
              "      <td>0.01094</td>\n",
              "      <td>0.01367</td>\n",
              "      <td>0.02279</td>\n",
              "      <td>0.02005</td>\n",
              "      <td>0.04102</td>\n",
              "      <td>0.00091</td>\n",
              "      <td>0.00091</td>\n",
              "      <td>0.00638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13024</th>\n",
              "      <td>pri</td>\n",
              "      <td>1</td>\n",
              "      <td>9601</td>\n",
              "      <td>2067</td>\n",
              "      <td>mitochondrion Pongo pygmaeus abelii</td>\n",
              "      <td>0.01258</td>\n",
              "      <td>0.03193</td>\n",
              "      <td>0.01984</td>\n",
              "      <td>0.00629</td>\n",
              "      <td>0.01451</td>\n",
              "      <td>0.05322</td>\n",
              "      <td>0.07644</td>\n",
              "      <td>0.01258</td>\n",
              "      <td>0.03096</td>\n",
              "      <td>0.06386</td>\n",
              "      <td>0.03435</td>\n",
              "      <td>0.01258</td>\n",
              "      <td>0.00629</td>\n",
              "      <td>0.01258</td>\n",
              "      <td>0.01451</td>\n",
              "      <td>0.00871</td>\n",
              "      <td>0.01161</td>\n",
              "      <td>0.03338</td>\n",
              "      <td>0.02129</td>\n",
              "      <td>0.00242</td>\n",
              "      <td>0.00871</td>\n",
              "      <td>0.03338</td>\n",
              "      <td>0.01984</td>\n",
              "      <td>0.00048</td>\n",
              "      <td>0.00387</td>\n",
              "      <td>0.00774</td>\n",
              "      <td>0.01693</td>\n",
              "      <td>0.01451</td>\n",
              "      <td>0.01113</td>\n",
              "      <td>0.01016</td>\n",
              "      <td>0.02032</td>\n",
              "      <td>0.02371</td>\n",
              "      <td>0.00145</td>\n",
              "      <td>0.00339</td>\n",
              "      <td>0.01161</td>\n",
              "      <td>0.01451</td>\n",
              "      <td>0.05031</td>\n",
              "      <td>0.02854</td>\n",
              "      <td>0.00484</td>\n",
              "      <td>0.01016</td>\n",
              "      <td>0.02080</td>\n",
              "      <td>0.02177</td>\n",
              "      <td>0.00339</td>\n",
              "      <td>0.00822</td>\n",
              "      <td>0.03532</td>\n",
              "      <td>0.00242</td>\n",
              "      <td>0.00435</td>\n",
              "      <td>0.00290</td>\n",
              "      <td>0.01693</td>\n",
              "      <td>0.02661</td>\n",
              "      <td>0.00290</td>\n",
              "      <td>0.00097</td>\n",
              "      <td>0.00726</td>\n",
              "      <td>0.00629</td>\n",
              "      <td>0.00145</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00048</td>\n",
              "      <td>0.00194</td>\n",
              "      <td>0.01306</td>\n",
              "      <td>0.01838</td>\n",
              "      <td>0.00677</td>\n",
              "      <td>0.00242</td>\n",
              "      <td>0.00097</td>\n",
              "      <td>0.01887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13025</th>\n",
              "      <td>pri</td>\n",
              "      <td>1</td>\n",
              "      <td>9602</td>\n",
              "      <td>1686</td>\n",
              "      <td>mitochondrion Pongo pygmaeus pygmaeus</td>\n",
              "      <td>0.01423</td>\n",
              "      <td>0.03321</td>\n",
              "      <td>0.01661</td>\n",
              "      <td>0.00356</td>\n",
              "      <td>0.01127</td>\n",
              "      <td>0.05042</td>\n",
              "      <td>0.09609</td>\n",
              "      <td>0.01068</td>\n",
              "      <td>0.02728</td>\n",
              "      <td>0.06643</td>\n",
              "      <td>0.02669</td>\n",
              "      <td>0.01246</td>\n",
              "      <td>0.00297</td>\n",
              "      <td>0.01542</td>\n",
              "      <td>0.01423</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00949</td>\n",
              "      <td>0.03915</td>\n",
              "      <td>0.01720</td>\n",
              "      <td>0.00119</td>\n",
              "      <td>0.00830</td>\n",
              "      <td>0.04033</td>\n",
              "      <td>0.02372</td>\n",
              "      <td>0.00119</td>\n",
              "      <td>0.00237</td>\n",
              "      <td>0.00237</td>\n",
              "      <td>0.02017</td>\n",
              "      <td>0.01423</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00593</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.02610</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00119</td>\n",
              "      <td>0.00830</td>\n",
              "      <td>0.01661</td>\n",
              "      <td>0.05279</td>\n",
              "      <td>0.03618</td>\n",
              "      <td>0.00712</td>\n",
              "      <td>0.00712</td>\n",
              "      <td>0.02017</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.00830</td>\n",
              "      <td>0.00652</td>\n",
              "      <td>0.03203</td>\n",
              "      <td>0.00119</td>\n",
              "      <td>0.00356</td>\n",
              "      <td>0.00474</td>\n",
              "      <td>0.02017</td>\n",
              "      <td>0.02432</td>\n",
              "      <td>0.00297</td>\n",
              "      <td>0.00119</td>\n",
              "      <td>0.00830</td>\n",
              "      <td>0.01186</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00178</td>\n",
              "      <td>0.01661</td>\n",
              "      <td>0.02788</td>\n",
              "      <td>0.00297</td>\n",
              "      <td>0.00356</td>\n",
              "      <td>0.00119</td>\n",
              "      <td>0.02017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13026</th>\n",
              "      <td>pri</td>\n",
              "      <td>0</td>\n",
              "      <td>9606</td>\n",
              "      <td>40662582</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>0.01757</td>\n",
              "      <td>0.02028</td>\n",
              "      <td>0.00767</td>\n",
              "      <td>0.01293</td>\n",
              "      <td>0.01319</td>\n",
              "      <td>0.01959</td>\n",
              "      <td>0.00715</td>\n",
              "      <td>0.03964</td>\n",
              "      <td>0.01600</td>\n",
              "      <td>0.02082</td>\n",
              "      <td>0.00749</td>\n",
              "      <td>0.02204</td>\n",
              "      <td>0.01103</td>\n",
              "      <td>0.01446</td>\n",
              "      <td>0.00708</td>\n",
              "      <td>0.02812</td>\n",
              "      <td>0.01845</td>\n",
              "      <td>0.02773</td>\n",
              "      <td>0.01582</td>\n",
              "      <td>0.00737</td>\n",
              "      <td>0.01754</td>\n",
              "      <td>0.01979</td>\n",
              "      <td>0.01692</td>\n",
              "      <td>0.00692</td>\n",
              "      <td>0.01317</td>\n",
              "      <td>0.01075</td>\n",
              "      <td>0.02222</td>\n",
              "      <td>0.01647</td>\n",
              "      <td>0.01647</td>\n",
              "      <td>0.01522</td>\n",
              "      <td>0.01768</td>\n",
              "      <td>0.01221</td>\n",
              "      <td>0.00441</td>\n",
              "      <td>0.01213</td>\n",
              "      <td>0.01946</td>\n",
              "      <td>0.01312</td>\n",
              "      <td>0.01889</td>\n",
              "      <td>0.01511</td>\n",
              "      <td>0.00605</td>\n",
              "      <td>0.01219</td>\n",
              "      <td>0.01531</td>\n",
              "      <td>0.01234</td>\n",
              "      <td>0.03423</td>\n",
              "      <td>0.01696</td>\n",
              "      <td>0.01910</td>\n",
              "      <td>0.01058</td>\n",
              "      <td>0.01262</td>\n",
              "      <td>0.01086</td>\n",
              "      <td>0.01509</td>\n",
              "      <td>0.02444</td>\n",
              "      <td>0.03186</td>\n",
              "      <td>0.00454</td>\n",
              "      <td>0.01042</td>\n",
              "      <td>0.00617</td>\n",
              "      <td>0.01142</td>\n",
              "      <td>0.01217</td>\n",
              "      <td>0.01196</td>\n",
              "      <td>0.02178</td>\n",
              "      <td>0.02510</td>\n",
              "      <td>0.02896</td>\n",
              "      <td>0.03959</td>\n",
              "      <td>0.00099</td>\n",
              "      <td>0.00079</td>\n",
              "      <td>0.00156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13027</th>\n",
              "      <td>pri</td>\n",
              "      <td>1</td>\n",
              "      <td>9606</td>\n",
              "      <td>8998998</td>\n",
              "      <td>mitochondrion Homo sapiens</td>\n",
              "      <td>0.01778</td>\n",
              "      <td>0.03724</td>\n",
              "      <td>0.01732</td>\n",
              "      <td>0.00600</td>\n",
              "      <td>0.01689</td>\n",
              "      <td>0.03854</td>\n",
              "      <td>0.07000</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.03391</td>\n",
              "      <td>0.05137</td>\n",
              "      <td>0.04406</td>\n",
              "      <td>0.01225</td>\n",
              "      <td>0.01065</td>\n",
              "      <td>0.01415</td>\n",
              "      <td>0.01953</td>\n",
              "      <td>0.00661</td>\n",
              "      <td>0.01402</td>\n",
              "      <td>0.02956</td>\n",
              "      <td>0.02377</td>\n",
              "      <td>0.00319</td>\n",
              "      <td>0.01132</td>\n",
              "      <td>0.03343</td>\n",
              "      <td>0.01180</td>\n",
              "      <td>0.00177</td>\n",
              "      <td>0.00241</td>\n",
              "      <td>0.00891</td>\n",
              "      <td>0.02079</td>\n",
              "      <td>0.01952</td>\n",
              "      <td>0.00961</td>\n",
              "      <td>0.00969</td>\n",
              "      <td>0.02291</td>\n",
              "      <td>0.01920</td>\n",
              "      <td>0.00238</td>\n",
              "      <td>0.00355</td>\n",
              "      <td>0.00970</td>\n",
              "      <td>0.01463</td>\n",
              "      <td>0.04147</td>\n",
              "      <td>0.03269</td>\n",
              "      <td>0.00257</td>\n",
              "      <td>0.01292</td>\n",
              "      <td>0.02223</td>\n",
              "      <td>0.02051</td>\n",
              "      <td>0.00270</td>\n",
              "      <td>0.01055</td>\n",
              "      <td>0.03408</td>\n",
              "      <td>0.00166</td>\n",
              "      <td>0.00456</td>\n",
              "      <td>0.00404</td>\n",
              "      <td>0.01802</td>\n",
              "      <td>0.02358</td>\n",
              "      <td>0.00304</td>\n",
              "      <td>0.00277</td>\n",
              "      <td>0.00571</td>\n",
              "      <td>0.00653</td>\n",
              "      <td>0.00083</td>\n",
              "      <td>0.00041</td>\n",
              "      <td>0.00041</td>\n",
              "      <td>0.00451</td>\n",
              "      <td>0.01402</td>\n",
              "      <td>0.01651</td>\n",
              "      <td>0.00783</td>\n",
              "      <td>0.00156</td>\n",
              "      <td>0.00114</td>\n",
              "      <td>0.02161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13028 rows × 69 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Kingdom  DNAtype  SpeciesID   Ncodons  ...      GAG      UAA      UAG      UGA\n",
              "0         vrl        0     100217      1995  ...  0.04361  0.00251  0.00050  0.00000\n",
              "1         vrl        0     100220      1474  ...  0.04410  0.00271  0.00068  0.00000\n",
              "2         vrl        0     100755      4862  ...  0.02468  0.00391  0.00000  0.00144\n",
              "3         vrl        0     100880      1915  ...  0.03446  0.00261  0.00157  0.00000\n",
              "4         vrl        0     100887     22831  ...  0.03679  0.00000  0.00044  0.00131\n",
              "...       ...      ...        ...       ...  ...      ...      ...      ...      ...\n",
              "13023     pri        0       9601      1097  ...  0.04102  0.00091  0.00091  0.00638\n",
              "13024     pri        1       9601      2067  ...  0.00677  0.00242  0.00097  0.01887\n",
              "13025     pri        1       9602      1686  ...  0.00297  0.00356  0.00119  0.02017\n",
              "13026     pri        0       9606  40662582  ...  0.03959  0.00099  0.00079  0.00156\n",
              "13027     pri        1       9606   8998998  ...  0.00783  0.00156  0.00114  0.02161\n",
              "\n",
              "[13028 rows x 69 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw7tngrUkUmf",
        "tags": []
      },
      "source": [
        "def ML_prepocess(data): \n",
        "  ml_data = data.copy()\n",
        "  ml_data.Kingdom = ml_data.Kingdom.astype('category')\n",
        "  drop_col = ['SpeciesID','SpeciesName','Ncodons']\n",
        "  print(\"Columnas eliminadas:\", drop_col)\n",
        "  ml_data.drop(drop_col,inplace=True, axis=1)\n",
        "\n",
        "  ml_data[['UUU', 'UUC']] = ml_data[['UUU', 'UUC']].apply(pd.to_numeric, errors='coerce')\n",
        "  criteria = ~ml_data.isna()\n",
        "  ml_data = ml_data[criteria['UUU']]\n",
        "  ml_data = ml_data[criteria['UUC']]\n",
        "  return ml_data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fonq0MwAfNrZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "5456de99-3dea-4096-cebd-d54f7da6a37e"
      },
      "source": [
        "ml_data = ML_prepocess(dataset)\n",
        "ml_data.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-84d99d38f520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mml_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mML_prepocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mml_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uiswejYflDwF",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "source": [
        "def Create_X_Y(ml_data, target_col): #Modelo secuencial\n",
        "  x = ml_data.drop(target_col, axis=1)\n",
        "  y = ml_data[target_col]\n",
        "\n",
        "  #enc = OneHotEncoder(handle_unknown='ignore')\n",
        "  #enc.fit(y)\n",
        "  #print(enc.categories_)\n",
        "  #dummy_y = enc.transform(y)\n",
        "\n",
        "  #encoder = LabelEncoder()\n",
        "  #encoder.fit(y[target_col[0]])\n",
        "  #encoded_Y = encoder.transform(y[target_col[0]])\n",
        "  #dummy_y = tf.keras.utils.to_categorical(encoded_Y, num_classes=y.value_counts().index.shape[0])\n",
        "\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y[target_col[0]])\n",
        "  print(lb.classes_)\n",
        "  dummy_y = lb.transform(y[target_col[0]])\n",
        "  df_y_1 = pd.DataFrame(dummy_y, columns = lb.classes_)\n",
        "  \n",
        "  lb.fit(y[target_col[1]])\n",
        "  print(lb.classes_)\n",
        "  dummy_y = lb.transform(y[target_col[1]])\n",
        "  df_y_2 = pd.DataFrame(dummy_y, columns = lb.classes_)\n",
        "  result = pd.concat([df_y_1, df_y_2], axis=1)\n",
        "\n",
        "  #x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=70)\n",
        "  return x, df_y_1, df_y_2, result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-E222IWlNtH"
      },
      "source": [
        "target_col = ['Kingdom', 'DNAtype']\n",
        "X, df_y_1, df_y_2, Y = Create_X_Y(ml_data, target_col)\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd96ZUmM_sEm"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=70)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train.values, y_train.values))\n",
        "train_dataset = dataset.shuffle(len(X) + len(Y), reshuffle_each_iteration=True).batch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJqstIP__th0"
      },
      "source": [
        "def get_compiled_model():\n",
        "  ml_model = tf.keras.Sequential([\n",
        "    #tf.keras.layers.BatchNormalization(input_shape=(preprocessed_dataset.shape[1]-1,)),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    #tf.keras.layers.Dropout(.2),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    #tf.keras.layers.Dropout(.2),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    #tf.keras.layers.Dropout(.2),\n",
        "    #tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(22, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  ml_model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',#tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                metrics=[tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Accuracy(name='accuracy')])\n",
        "  return ml_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLrZCapM_vQy"
      },
      "source": [
        "ml_model = get_compiled_model()\n",
        "hist = ml_model.fit(train_dataset, validation_data=(x_test, y_test), epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQtoGLR3_xAi"
      },
      "source": [
        "ml_model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUaGzBABAD60"
      },
      "source": [
        "tf.keras.utils.plot_model(ml_model, to_file=\"model.png\", show_shapes=True, expand_nested=True, show_layer_names=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be4wWNIF_zEL"
      },
      "source": [
        "Modelo con 2 capas de salidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ck2kxFw_ylO"
      },
      "source": [
        "def get_compiled_model_2_output():\n",
        "  inp = tf.keras.layers.Input(shape=(64,))\n",
        "  l_x = tf.keras.layers.Dense(20, activation='relu', name= 'layer_1')(inp)\n",
        "  l_x = tf.keras.layers.Dense(20, activation='relu')(l_x)\n",
        "  \n",
        "  l_Kingdom = tf.keras.layers.Dense(20, activation='relu', name= 'K_1')(l_x)\n",
        "  l_Kingdom = tf.keras.layers.Dense(11, activation='softmax', name= 'K_out')(l_Kingdom)\n",
        "  \n",
        "  l_DNAtype = tf.keras.layers.Dense(20, activation='relu', name= 'DNA_1')(l_x)\n",
        "  l_DNAtype = tf.keras.layers.Dense(11, activation='softmax', name= 'DNA_out')(l_DNAtype)\n",
        "\n",
        "  ml_model = tf.keras.Model(inputs=inp, outputs=[l_Kingdom, l_DNAtype])\n",
        "\n",
        "  ml_model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',#tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                metrics=[tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Accuracy(name='accuracy')])\n",
        "  return ml_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJa7_fIb_44H"
      },
      "source": [
        "x_train, x_test, y_K_train, y_K_test, y_DNA_train, y_DNA_test = train_test_split(X, df_y_1, df_y_2, test_size=0.2, random_state=70)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_K_train, y_DNA_train))\n",
        "train_dataset = dataset.shuffle(len(X) + len(df_y_1) + + len(df_y_2), reshuffle_each_iteration=True).batch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts_Sj0sa_6Mc"
      },
      "source": [
        "ml_model = get_compiled_model_2_output()\n",
        "#hist = ml_model.fit(x_train, [y_K_train, y_DNA_train], validation_data=(x_test, y_K_test, y_DNA_test), epochs=10)\n",
        "hist = ml_model.fit(x_train, [y_K_train, y_DNA_train], epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpJ0n4Wz_8NJ"
      },
      "source": [
        "tf_prediction = ml_model.predict(x_test)\n",
        "tf_prediction = tf.cast(tf.greater(tf_prediction, 0.5), tf.int32).numpy()\n",
        "test_1 = pd.DataFrame(data= tf_prediction[0], columns = df_y_1.columns)#, columns = lb.classes_)\n",
        "test_2 = pd.DataFrame(data= tf_prediction[1], columns = df_y_2.columns)#, columns = lb.classes_)\n",
        "test_3 = pd.concat([test_1, test_2], axis=1)\n",
        "test_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA5rbEFt_92w"
      },
      "source": [
        "ml_model.evaluate(x_test, [y_K_test, y_DNA_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTHo55ct__Zj"
      },
      "source": [
        "tf.keras.utils.plot_model(ml_model, to_file=\"model.png\", show_shapes=True, expand_nested=True, show_layer_names=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrG1ghwNxxxU"
      },
      "source": [
        "##Seleccion de Caracteristicas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyhXOrso044O"
      },
      "source": [
        "###Por Filtrado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_OJjc93x6wf"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75BIM1pGzFGN"
      },
      "source": [
        "#Implementamos una filtrado usando `mutual_info_classif` no podemos usar chi2 porque tenemos valores negatiivos\n",
        "filtrado = SelectKBest(mutual_info_classif, k=5).fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQGgz6WC0fpR"
      },
      "source": [
        "filtrado.scores_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLcABiQ_0kBQ"
      },
      "source": [
        "X_new = filtrado.transform(x_train)\n",
        "X_new[:5] #Vemos nuestro set de featuers filtrado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qyZoxc-1qhF"
      },
      "source": [
        "**Implementamos un bucle por cada modelo y vemos los resutlados de usar las k caracteristicas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUzgrXBO0_ST"
      },
      "source": [
        "####Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVpuN2Dz025m"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  dt2 = DecisionTreeClassifier()\n",
        "  dt2.fit(X_new, y_train)\n",
        "  acc = dt2.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, dt2.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RH2Zy-E26ju"
      },
      "source": [
        "####Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bOZArmj20NU",
        "tags": []
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  rt2 = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "  rt2.fit(X_new, y_train)\n",
        "  acc = rt2.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, rt2.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omEtZ7oS34fu"
      },
      "source": [
        "####KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAO5pHJL37eF"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  n_neighbors = 4\n",
        "  knn2 = KNeighborsClassifier(n_neighbors)\n",
        "  knn2.fit(X_new, y_train)\n",
        "  acc = knn2.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, knn2.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICi77fnpzSYD"
      },
      "source": [
        "####XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Rjby5OzRQI"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  xgb=XGBClassifier(n_estimators=80,  max_depth=10)\n",
        "  xgb.fit(X_new, y_train)\n",
        "  acc = xgb.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, xgb.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDgilyLFzpkm"
      },
      "source": [
        "#### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-ORNWEazk6X"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(65):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  mdl = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "  mdl.fit(X_new, y_train)\n",
        "  acc = mdl.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, mdl.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0N79nw79tDF"
      },
      "source": [
        "####NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IeulMOT9qvp"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "lr = 0.01\n",
        "bs = 256\n",
        "epochs = 30\n",
        "X = x_train\n",
        "Y = y_train\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(X, Y)\n",
        "  X_new = filter.transform(X)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  x_train, x_val, y_train, y_val = train_test_split(X_new, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "  nn2 = Sequential([\n",
        "      Dense(12, activation='softmax', input_shape=((n+1),))\n",
        "  ])\n",
        "\n",
        "  nn2.compile(optimizer=SGD(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  nn2.fit(x_train, y_train, batch_size=bs, epochs=epochs, validation_data=(x_val, y_val), verbose=0 )\n",
        "  xt_predict = np.argmax(nn2.predict(Xt_new), axis=1)\n",
        "\n",
        "  f1 = f1_score(Yt, xt_predict, average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1)\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu89MjoXG_jI"
      },
      "source": [
        "###Por wrapping - Backward elimination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK4KJakpKhdQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqZtnk4hMYC-"
      },
      "source": [
        "**Apilcamos a cada modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fofLcjwqKves"
      },
      "source": [
        "####Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn_MNWe8HIed"
      },
      "source": [
        "model = DecisionTreeClassifier()\n",
        "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(2),scoring='accuracy')\n",
        "rfecv.fit(X, Y1)\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SKnHPTrMdF8"
      },
      "source": [
        "rfecv.n_features_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0-szYWcMpzJ"
      },
      "source": [
        "X_new = rfecv.transform(X)\n",
        "Xt_new = rfecv.transform(Xt)\n",
        "dt3 = DecisionTreeClassifier()\n",
        "dt3.fit(X_new, Y1)\n",
        "acc = dt3.score(Xt_new, Yt)\n",
        "f1 = f1_score(Yt, dt3.predict(Xt_new), average='weighted')\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuDm1TczKyaU"
      },
      "source": [
        "####Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hkyFRxqKsZq"
      },
      "source": [
        "model = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(2),scoring='accuracy')\n",
        "rfecv.fit(X, Y1)\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQwPj4X8MhTR"
      },
      "source": [
        "rfecv.n_features_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3aehAC0NJ6g"
      },
      "source": [
        "X_new = rfecv.transform(X)\n",
        "Xt_new = rfecv.transform(Xt)\n",
        "rf3 = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "rf3.fit(X_new, Y1)\n",
        "acc = rf3.score(Xt_new, Yt)\n",
        "f1 = f1_score(Yt, rf3.predict(Xt_new), average='weighted')\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZXI25XV0EEA"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv8Q-OIq066Q"
      },
      "source": [
        "xgb=XGBClassifier(n_estimators=80,  max_depth=10)\n",
        "rfecv = RFECV(estimator=xgb, step=1, cv=4,scoring='accuracy')\n",
        "rfecv.fit(X, Y1)\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuwCscQ21Vcx"
      },
      "source": [
        "rfecv.n_features_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHGujZ2u1V31"
      },
      "source": [
        "X_new = rfecv.transform(X)\n",
        "Xt_new = rfecv.transform(Xt)\n",
        "xgb = XGBClassifier(n_estimators=80,  max_depth=10)\n",
        "xgb.fit(X_new, Y1)\n",
        "acc = xgb.score(Xt_new, Yt)\n",
        "f1 = f1_score(Yt, xgb.predict(Xt_new), average='weighted')\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pllv3F2s07Nt"
      },
      "source": [
        "####LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6NG5uhq1YCJ"
      },
      "source": [
        "model = LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "rfecv = RFECV(estimator=model, step=1, cv=4,scoring='accuracy')\n",
        "rfecv.fit(X, Y1)\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Q4VPK81X8D"
      },
      "source": [
        "rfecv.n_features_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw6bzkAx1Xxp"
      },
      "source": [
        "X_new = rfecv.transform(X)\n",
        "Xt_new = rfecv.transform(Xt)\n",
        "model = LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "model.fit(X_new, Y1)\n",
        "acc = model.score(Xt_new, Yt)\n",
        "f1 = f1_score(Yt, model.predict(Xt_new), average='weighted')\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOBecEO4LCr0"
      },
      "source": [
        "####KNN y Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpJthuZJLXqL"
      },
      "source": [
        "KNN no expone la importancia de los features asi que no se puede analizar con RFECV y en las Neural Network tambien es complicado extraer esa informacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0xJ5i9XMVp0"
      },
      "source": [
        "###PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WElZhMLOHHK"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZnJheBiUo7P"
      },
      "source": [
        "pca = PCA().fit(X)\n",
        "pd.DataFrame(pca.components_, columns=X.columns).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcitFOYSVHxG"
      },
      "source": [
        "per_var = np.round(pca.explained_variance_ratio_*100, decimals=5)\n",
        "labels = ['PC' + str(x) for x in range(1, len(per_var) + 1)]\n",
        "plt.plot(labels, np.cumsum(pca.explained_variance_ratio_), '-s')\n",
        "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
        "#plt.rcParams['figure.figsize'] = 5, 60\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9enNdwpXThG",
        "tags": []
      },
      "source": [
        "plt.bar(x=range(1, len(per_var) + 1), height=per_var, tick_label = labels)\n",
        "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu9MlDOSqExc"
      },
      "source": [
        "####Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1p21YEJpuoy"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  dt4 = DecisionTreeClassifier()\n",
        "  dt4.fit(X_new, Y1)\n",
        "  acc = dt4.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, dt4.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beE4h-4ZNhE4"
      },
      "source": [
        "####Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn17SjcRrmfZ"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  rf4 = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "  rf4.fit(X_new, Y1)\n",
        "  acc = rf4.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, rf4.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nImaIJD2Xhg"
      },
      "source": [
        "####XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cINn9Y92gvn"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  model = XGBClassifier(n_estimators=80,  max_depth=10)\n",
        "  model.fit(X_new, Y1)\n",
        "  acc = model.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, model.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK-wod5Z2eeT"
      },
      "source": [
        "####Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIxINZY32eWG"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  model = LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "  model.fit(X_new, Y1)\n",
        "  acc = model.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, model.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZBFYDMPNlpO"
      },
      "source": [
        "####KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIDd9loXuTwL"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  knn4 = KNeighborsClassifier(4)\n",
        "  knn4.fit(X_new, Y1)\n",
        "  acc = knn4.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, knn4.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_DEMpQgfNrp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}