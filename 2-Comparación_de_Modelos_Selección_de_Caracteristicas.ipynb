{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparación de Modelos  - Selección de Caracteristicas",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmenesesrivera/codonusagebias/blob/main/2-Comparaci%C3%B3n_de_Modelos_Selecci%C3%B3n_de_Caracteristicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao5Xptodqtxp"
      },
      "source": [
        "##Comparación de Modelos  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TxYDgErqyHG"
      },
      "source": [
        "###Lectura de la Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PphHXFEffNrH"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile, urllib.request, shutil\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00577/codon_usage.csv.zip'\n",
        "filename = 'codon_usage.csv.zip'"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-sYKioZfNrI"
      },
      "source": [
        "with urllib.request.urlopen(url) as response, open(filename, 'wb') as out_file:\n",
        "    shutil.copyfileobj(response, out_file)\n",
        "    with zipfile.ZipFile(filename) as zf:\n",
        "        zf.extractall()"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvFBz9_ufNrJ",
        "outputId": "3736ba36-1d7d-40f8-a534-0d8ca893ddf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip codon_usage.csv"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  codon_usage.csv\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "Archive:  codon_usage.csv.zip\n",
            "replace codon_usage.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: codon_usage.csv         \n",
            "replace __MACOSX/._codon_usage.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._codon_usage.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttXoBVYCrPGR",
        "tags": []
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow.python.keras, math\n",
        "from sklearn.model_selection import train_test_split\n",
        "labelencoder = LabelEncoder()"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nXffYItfNrL",
        "outputId": "a671d7da-7146-4722-a0fc-23eca5a11710",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Lectura del dataset\n",
        "file_name = \"codon_usage.csv\"\n",
        "dataset = pd.read_csv(file_name,  header=None)\n",
        "# Eliminando columnas inválidas\n",
        "columns = dataset.iloc[0]\n",
        "dataset.columns = columns\n",
        "dataset = dataset.drop([0],axis=0)\n",
        "\n",
        "cols = dataset.columns[dataset.dtypes.eq(object)] # Seleccionamos las columnas con el tipo de datao : Object\n",
        "dataset = dataset[cols].apply(pd.to_numeric, errors='ignore') #se transforma\n",
        "\n",
        "# Se observa que hay datos str que no permiten manipular los demás como numéricos, por lo tanto se va a forzar.\n",
        "dataset[['UUU', 'UUC']] = dataset[['UUU', 'UUC']].apply(pd.to_numeric, errors='coerce')\n",
        "null_percentages = dataset['UUU'].isna().sum()\n",
        "null_percentages\n",
        "\n"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1,2,3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qhbTi-KfNrM"
      },
      "source": [
        "def preprocess_dataset(dataset, save_metadata=True):\n",
        "  \n",
        "  preprocessed_dataset = dataset.copy()\n",
        "\n",
        "  #Determinamos aquellas variables que tengan un porcentaje de registros únicos por cada variable mayor al valor de 0.7\n",
        "  threshold = 0.7\n",
        "\n",
        "  unique_percentages = dataset.nunique() / len(dataset)\n",
        "\n",
        "  criteria = unique_percentages > threshold\n",
        "\n",
        "  columns_to_filter = unique_percentages[criteria].keys()\n",
        "  \n",
        "  # Está columna contiene datos descriptivos, por tanto será transformada a str.\n",
        "\n",
        "  preprocessed_dataset['SpeciesName'] = preprocessed_dataset['SpeciesName'].astype(str)\n",
        "  preprocessed_dataset['SpeciesName']\n",
        " \n",
        "  #Eliminamos las variables seleccionadas en el paso anterior\n",
        "  preprocessed_dataset.drop(columns_to_filter, axis=1, inplace=True)\n",
        " \n",
        "  #Eliminamos los registros duplicados\n",
        "  preprocessed_dataset.drop_duplicates(keep=\"first\", inplace=True)\n",
        "\n",
        "  #Determinamos que variables son del tipo númerico y cuales son categóricas\n",
        "  numeric_columns = list()\n",
        "  categorical_columns = list()\n",
        "  dictionary_of_columns_with_index_to_categorical = dict()\n",
        "  dictionary_of_columns_with_categorical_to_index = dict()\n",
        "\n",
        "  for column in preprocessed_dataset:\n",
        "    #Determinamos si la variable es numérica o no\n",
        "    if pd.api.types.is_numeric_dtype(preprocessed_dataset[column]):\n",
        "      numeric_columns.append(column)\n",
        "    else:\n",
        "      #Modificamos el tipo de dato de la variable mediante \"astype\"\n",
        "      preprocessed_dataset[column] = preprocessed_dataset[column].astype(\"category\")\n",
        "\n",
        "      #Verificamos si el tipo de dato de la variable fue transformado a categórico correctamente\n",
        "      if not pd.api.types.is_categorical_dtype(preprocessed_dataset[column]):\n",
        "        raise Exception(\"La columna {} no se transformó correctamente a categórica\".format(column))\n",
        "\n",
        "      dictionary_of_columns_with_index_to_categorical[column] = dict()\n",
        "      dictionary_of_columns_with_categorical_to_index[column] = dict()\n",
        "      \n",
        "      #Indexamos los valores (categorías), sin tomar en consideración los nulos, de la variable y guardamos esa información en los diccionarios\n",
        "      for index, category in enumerate(preprocessed_dataset[column].cat.categories):\n",
        "        dictionary_of_columns_with_index_to_categorical[column][index] = category\n",
        "        dictionary_of_columns_with_categorical_to_index[column][category] = index\n",
        "      \n",
        "      categorical_columns.append(column)\n",
        "  \n",
        "  #Reemplazamos los nulos con la mediana sólo de aquellas variables numéricas\n",
        "    median_of_numeric_columns = preprocessed_dataset[numeric_columns].median()\n",
        "    preprocessed_dataset[numeric_columns] = preprocessed_dataset[numeric_columns].fillna(median_of_numeric_columns)\n",
        "\n",
        "  #Transformamos a números los valores (categorías) de las variables categóricas sin considerar los nulos\n",
        "  preprocessed_dataset.replace(dictionary_of_columns_with_categorical_to_index, inplace=True)\n",
        "\n",
        "  #Determinamos aquellas variables que tengan un porcentaje de registros nulos por cada variable mayor al valor de 0.7\n",
        "  threshold = 0.7\n",
        "\n",
        "  null_percentages = preprocessed_dataset[categorical_columns].isna().sum() / len(preprocessed_dataset)\n",
        "\n",
        "  criteria = null_percentages > threshold\n",
        "\n",
        "  columns_to_filter = null_percentages[criteria].keys()\n",
        "\n",
        "  #Eliminamos las variables seleccionadas en el paso anterior\n",
        "  preprocessed_dataset.drop(columns_to_filter, axis=1, inplace=True)\n",
        "\n",
        "  #Eliminamos los registros duplicados\n",
        "  preprocessed_dataset.drop_duplicates(keep=\"first\", inplace=True)\n",
        " \n",
        "  return preprocessed_dataset"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5QCuYFYfNrN"
      },
      "source": [
        "preprocessed_dataset = preprocess_dataset(dataset)\n"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_wggFtPhbkL",
        "outputId": "5d3b1b7a-525e-43d1-9700-3f5af86ec3e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "preprocessed_dataset.describe"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of 0      Kingdom  DNAtype   Ncodons      UUU  ...      GAG      UAA      UAG      UGA\n",
              "1            9        0      1995  0.01654  ...  0.04361  0.00251  0.00050  0.00000\n",
              "2            9        0      1474  0.02714  ...  0.04410  0.00271  0.00068  0.00000\n",
              "3            9        0      4862  0.01974  ...  0.02468  0.00391  0.00000  0.00144\n",
              "4            9        0      1915  0.01775  ...  0.03446  0.00261  0.00157  0.00000\n",
              "5            9        0     22831  0.02816  ...  0.03679  0.00000  0.00044  0.00131\n",
              "...        ...      ...       ...      ...  ...      ...      ...      ...      ...\n",
              "13024        7        0      1097  0.02552  ...  0.04102  0.00091  0.00091  0.00638\n",
              "13025        7        1      2067  0.01258  ...  0.00677  0.00242  0.00097  0.01887\n",
              "13026        7        1      1686  0.01423  ...  0.00297  0.00356  0.00119  0.02017\n",
              "13027        7        0  40662582  0.01757  ...  0.03959  0.00099  0.00079  0.00156\n",
              "13028        7        1   8998998  0.01778  ...  0.00783  0.00156  0.00114  0.02161\n",
              "\n",
              "[12991 rows x 67 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVy-AIUjfNrP"
      },
      "source": [
        "#Separamos las columnas  Reino y ADN  , respectivamente.\n",
        "X1 = preprocessed_dataset.drop(\"Kingdom\", axis=1)\n",
        "X2 = preprocessed_dataset.drop(\"DNAtype\", axis=1)\n",
        "Y1 = preprocessed_dataset[\"Kingdom\"]  \n",
        "Y2 = preprocessed_dataset[\"DNAtype\"] "
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkSzfWZOfNrQ"
      },
      "source": [
        "#Mediante el método \"train_test_split\" usaremos el 20% de la data para probar el modelo. El parámetro \"random state\" nos sirve para\n",
        "#poder replicar la misma separación\n",
        "x_train, Xt, y_train, Yt = train_test_split(X1, Y1, test_size=0.2, random_state=70)"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bLFpoKEk_4q"
      },
      "source": [
        "#Mediante el método \"train_test_split\" usaremos el 20% de la data para probar el modelo. El parámetro \"random state\" nos sirve para\n",
        "#poder replicar la misma separación\n",
        "x2_train, Xt2, y2_train, Yt2 = train_test_split(X2, Y2, test_size=0.2, random_state=70)"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b558tq8I-1mU"
      },
      "source": [
        "Ahora vamos a probar los modelos sin tunearlos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POJRvjNhtbRF"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uExErJ5xkwzn"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mj8C8rYsi3w",
        "outputId": "cdcef903-acf7-45c9-ba15-bc50b5567955"
      },
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train, y_train) #Entrenamos un Decision Tree tunear"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwU3DHdutOKT",
        "outputId": "aeca0cc2-7925-4b99-ac05-c89518c4d5a6"
      },
      "source": [
        "f1_score(Yt, dt.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7714955449405004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnhb-9Xkkzty"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kTPg8pnkzNo",
        "outputId": "563d104d-35ba-4995-9e64-5bc473778e47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dt2 = DecisionTreeClassifier()\n",
        "dt2.fit(x2_train, y2_train) #Entrenamos un Decision Tree tunear"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdyMBoG2ky3Y",
        "outputId": "4fa6e1a9-8920-424e-a7f3-7cb4fe30ce68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "f1_score(Yt2, dt2.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.974913794959661"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5R9WwtDtemd"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvoLca-almK0"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThNghRCdthLR",
        "outputId": "dd4b5d88-d97b-426f-f79a-a662ca310456"
      },
      "source": [
        "rf = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "rf.fit(x_train, y_train) #Entrenamos un Random Forest sin tunear"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
              "                       oob_score=True, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP8HcMKduOn2",
        "outputId": "3b4bf441-11f3-4b78-8285-af9ac1536643"
      },
      "source": [
        "f1_score(Yt, rf.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8747286125156047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1BOEAWIlnCa"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xTU_A55lp5c",
        "outputId": "8084cb1f-d965-47d6-ae3d-a4f0563d4de3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rf2 = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "rf2.fit(x2_train, y2_train) #Entrenamos un Random Forest sin tunear"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
              "                       oob_score=True, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH-JtItbltBc",
        "outputId": "1bce59ad-c37a-42ca-de9d-e5be69be27c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "f1_score(Yt2, rf2.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9880422316034267"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Z8EBmBusht"
      },
      "source": [
        "##Clasificador K-Nearest Neighbor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWRFaGyMl02V"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8D9-CaXur1X",
        "outputId": "64994a43-eb94-4391-c802-67d5d6d961cf"
      },
      "source": [
        "n_neighbors = 4\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors)\n",
        "knn.fit(x_train, y_train) #Entrenamos un KNN sin tunear"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pxIn5Mwu3dp",
        "outputId": "bebddfd5-1d8f-4cb4-83f6-b8c516ba9b7f"
      },
      "source": [
        "f1_score(Yt, knn.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37425189253279567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAw4QUVAl15t"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRowqVZ8l3mB",
        "outputId": "7fbee945-b64f-49a7-d7e5-82fd130aee90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_neighbors = 4\n",
        "\n",
        "knn2 = KNeighborsClassifier(n_neighbors)\n",
        "knn2.fit(x2_train, y2_train) #Entrenamos un KNN sin tunear"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmx32Eikl5d_",
        "outputId": "f2fa61a2-ee54-494e-d83e-3163e5a3875b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "f1_score(Yt2, knn2.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7578392501379395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d97Ct07PiFMx"
      },
      "source": [
        "# Clasificador XGBost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN3PspfTmVUW"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltT6A_HmiFCZ",
        "outputId": "d997739e-7ea0-472a-ec84-03af63fcd900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " xgb=XGBClassifier(n_estimators=80,  max_depth=10)\n",
        " xgb.fit(x_train, y_train) #Entrenamos un XGBost sin tunear\n"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
              "              min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC-i__LMiCbj",
        "outputId": "0a9ebbe4-7d39-4c1b-8416-87ae1d5c2b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "f1_score(Yt, xgb.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9017597020186107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAkpR_mBmX8S"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40OPwDB9mY8T",
        "outputId": "6341067c-b001-41ce-bdc4-62bad359ef0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "xgb2=XGBClassifier(n_estimators=80, max_depth=10 )\n",
        "xgb2.fit(x2_train, y2_train) #Entrenamos un XGBost sin tunear\n"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
              "              min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZxJJnpmaso",
        "outputId": "73ab4ce5-ab14-4c2c-9051-3e0d07af9fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "f1_score(Yt2, xgb.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-242-0a8383c9d5f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Usamos F1 para comparar con otros modelos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                                                  validate_features=validate_features)\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1690\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['DNAtype', 'Ncodons', 'UUU', 'UUC', 'UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG', 'AUU', 'AUC', 'AUA', 'AUG', 'GUU', 'GUC', 'GUA', 'GUG', 'GCU', 'GCC', 'GCA', 'GCG', 'CCU', 'CCC', 'CCA', 'CCG', 'UGG', 'GGU', 'GGC', 'GGA', 'GGG', 'UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC', 'ACU', 'ACC', 'ACA', 'ACG', 'UAU', 'UAC', 'CAA', 'CAG', 'AAU', 'AAC', 'UGU', 'UGC', 'CAU', 'CAC', 'AAA', 'AAG', 'CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'GAU', 'GAC', 'GAA', 'GAG', 'UAA', 'UAG', 'UGA'] ['Kingdom', 'Ncodons', 'UUU', 'UUC', 'UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG', 'AUU', 'AUC', 'AUA', 'AUG', 'GUU', 'GUC', 'GUA', 'GUG', 'GCU', 'GCC', 'GCA', 'GCG', 'CCU', 'CCC', 'CCA', 'CCG', 'UGG', 'GGU', 'GGC', 'GGA', 'GGG', 'UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC', 'ACU', 'ACC', 'ACA', 'ACG', 'UAU', 'UAC', 'CAA', 'CAG', 'AAU', 'AAC', 'UGU', 'UGC', 'CAU', 'CAC', 'AAA', 'AAG', 'CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'GAU', 'GAC', 'GAA', 'GAG', 'UAA', 'UAG', 'UGA']\nexpected DNAtype in input data\ntraining data did not have the following fields: Kingdom"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4GmEyFGi9td"
      },
      "source": [
        "# Clasificador LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNx0kxemp1Xr"
      },
      "source": [
        "**Y1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZVOWCKwjAZi"
      },
      "source": [
        "mdl = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "mdl.fit(x_train, y_train) #Entrenamos un LightGBM sin tunear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lXfZzOGkHjW"
      },
      "source": [
        "f1_score(Yt, mdl.predict(Xt), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnGfMZnlpzo_"
      },
      "source": [
        "**Y2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FyDcK1CpzHU"
      },
      "source": [
        "mdl2 = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',max_depth = 10)\n",
        "mdl2.fit(x2_train, y2_train) #Entrenamos un XGBost sin tunear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdhITx5WpyyP"
      },
      "source": [
        "f1_score(Yt2, mdl2.predict(Xt2), average='weighted') #Usamos F1 para comparar con otros modelos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXjmRsBpyACd"
      },
      "source": [
        "# Redes neuronales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6knijcgew4L1"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow.python.keras, math\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw7tngrUkUmf",
        "tags": []
      },
      "source": [
        "lr = 0.01\n",
        "bs = 256\n",
        "epochs = 30\n",
        "#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fonq0MwAfNrZ"
      },
      "source": [
        "nn = Sequential([\n",
        "    Dense(12, activation='softmax', input_shape=(66,))\n",
        "])\n",
        "\n",
        "nn.compile(optimizer=SGD(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "nn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uiswejYflDwF",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "source": [
        "nn.fit(x_train, y_train, batch_size=bs, epochs=epochs, validation_data=(Xt, Yt)) #Entrenamos un NN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-E222IWlNtH"
      },
      "source": [
        "xt_predict = np.argmax(nn.predict(Xt), axis=1)\n",
        "f1_score(Yt, xt_predict, average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrG1ghwNxxxU"
      },
      "source": [
        "##Seleccion de Caracteristicas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyhXOrso044O"
      },
      "source": [
        "###Por Filtrado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_OJjc93x6wf"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75BIM1pGzFGN"
      },
      "source": [
        "#Implementamos una filtrado usando `mutual_info_classif` no podemos usar chi2 porque tenemos valores negatiivos\n",
        "filtrado = SelectKBest(mutual_info_classif, k=5).fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQGgz6WC0fpR"
      },
      "source": [
        "filtrado.scores_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLcABiQ_0kBQ"
      },
      "source": [
        "X_new = filtrado.transform(x_train)\n",
        "X_new[:5] #Vemos nuestro set de featuers filtrado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qyZoxc-1qhF"
      },
      "source": [
        "**Implementamos un bucle por cada modelo y vemos los resutlados de usar las k caracteristicas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUzgrXBO0_ST"
      },
      "source": [
        "####Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVpuN2Dz025m"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  dt2 = DecisionTreeClassifier()\n",
        "  dt2.fit(X_new, y_train)\n",
        "  acc = dt2.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, dt2.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RH2Zy-E26ju"
      },
      "source": [
        "####Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bOZArmj20NU",
        "tags": []
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  rt2 = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "  rt2.fit(X_new, y_train)\n",
        "  acc = rt2.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, rt2.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omEtZ7oS34fu"
      },
      "source": [
        "####KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAO5pHJL37eF"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  n_neighbors = 4\n",
        "  knn2 = KNeighborsClassifier(n_neighbors)\n",
        "  knn2.fit(X_new, y_train)\n",
        "  acc = knn2.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, knn2.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICi77fnpzSYD"
      },
      "source": [
        "####XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Rjby5OzRQI"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  xgb=XGBClassifier(n_estimators=80,  max_depth=10)\n",
        "  xgb.fit(X_new, y_train)\n",
        "  acc = xgb.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, xgb.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDgilyLFzpkm"
      },
      "source": [
        "#### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-ORNWEazk6X"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "for n in range(65):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(x_train, y_train)\n",
        "  X_new = filter.transform(x_train)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  mdl = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "  mdl.fit(X_new, y_train)\n",
        "  acc = mdl.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, mdl.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0N79nw79tDF"
      },
      "source": [
        "####NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IeulMOT9qvp"
      },
      "source": [
        "max = 0\n",
        "features = 0\n",
        "lr = 0.01\n",
        "bs = 256\n",
        "epochs = 30\n",
        "X = x_train\n",
        "Y = y_train\n",
        "for n in range(66):\n",
        "  filter = SelectKBest(mutual_info_classif, k=(n+1)).fit(X, Y)\n",
        "  X_new = filter.transform(X)\n",
        "  Xt_new = filter.transform(Xt)\n",
        "  x_train, x_val, y_train, y_val = train_test_split(X_new, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "  nn2 = Sequential([\n",
        "      Dense(12, activation='softmax', input_shape=((n+1),))\n",
        "  ])\n",
        "\n",
        "  nn2.compile(optimizer=SGD(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  nn2.fit(x_train, y_train, batch_size=bs, epochs=epochs, validation_data=(x_val, y_val), verbose=0 )\n",
        "  xt_predict = np.argmax(nn2.predict(Xt_new), axis=1)\n",
        "\n",
        "  f1 = f1_score(Yt, xt_predict, average='weighted')\n",
        "  print('Score usando ', (n+1), 'caracteristicas F1:',  f1)\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      features = n+1\n",
        "print('Mejor Score usando ', features, 'caracteristicas F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu89MjoXG_jI"
      },
      "source": [
        "###Por wrapping - Backward elimination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK4KJakpKhdQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqZtnk4hMYC-"
      },
      "source": [
        "**Apilcamos a cada modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fofLcjwqKves"
      },
      "source": [
        "####Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn_MNWe8HIed"
      },
      "source": [
        "model = DecisionTreeClassifier()\n",
        "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(2),scoring='accuracy')\n",
        "rfecv.fit(X, Y1)\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SKnHPTrMdF8"
      },
      "source": [
        "rfecv.n_features_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0-szYWcMpzJ"
      },
      "source": [
        "X_new = rfecv.transform(X)\n",
        "Xt_new = rfecv.transform(Xt)\n",
        "dt3 = DecisionTreeClassifier()\n",
        "dt3.fit(X_new, Y1)\n",
        "acc = dt3.score(Xt_new, Yt)\n",
        "f1 = f1_score(Yt, dt3.predict(Xt_new), average='weighted')\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuDm1TczKyaU"
      },
      "source": [
        "####Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hkyFRxqKsZq"
      },
      "source": [
        "model = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(2),scoring='accuracy')\n",
        "rfecv.fit(X, Y1)\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQwPj4X8MhTR"
      },
      "source": [
        "rfecv.n_features_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3aehAC0NJ6g"
      },
      "source": [
        "X_new = rfecv.transform(X)\n",
        "Xt_new = rfecv.transform(Xt)\n",
        "rf3 = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "rf3.fit(X_new, Y1)\n",
        "acc = rf3.score(Xt_new, Yt)\n",
        "f1 = f1_score(Yt, rf3.predict(Xt_new), average='weighted')\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZXI25XV0EEA"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv8Q-OIq066Q"
      },
      "source": [
        "xgb=XGBClassifier(n_estimators=80,  max_depth=10)\n",
        "rfecv = RFECV(estimator=xgb, step=1, cv=4,scoring='accuracy')\n",
        "rfecv.fit(X, Y1)\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuwCscQ21Vcx"
      },
      "source": [
        "rfecv.n_features_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHGujZ2u1V31"
      },
      "source": [
        "X_new = rfecv.transform(X)\n",
        "Xt_new = rfecv.transform(Xt)\n",
        "xgb = XGBClassifier(n_estimators=80,  max_depth=10)\n",
        "xgb.fit(X_new, Y1)\n",
        "acc = xgb.score(Xt_new, Yt)\n",
        "f1 = f1_score(Yt, xgb.predict(Xt_new), average='weighted')\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pllv3F2s07Nt"
      },
      "source": [
        "####LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6NG5uhq1YCJ"
      },
      "source": [
        "model = LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "rfecv = RFECV(estimator=model, step=1, cv=4,scoring='accuracy')\n",
        "rfecv.fit(X, Y1)\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Q4VPK81X8D"
      },
      "source": [
        "rfecv.n_features_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw6bzkAx1Xxp"
      },
      "source": [
        "X_new = rfecv.transform(X)\n",
        "Xt_new = rfecv.transform(Xt)\n",
        "model = LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "model.fit(X_new, Y1)\n",
        "acc = model.score(Xt_new, Yt)\n",
        "f1 = f1_score(Yt, model.predict(Xt_new), average='weighted')\n",
        "print('F1 Score: ', f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOBecEO4LCr0"
      },
      "source": [
        "####KNN y Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpJthuZJLXqL"
      },
      "source": [
        "KNN no expone la importancia de los features asi que no se puede analizar con RFECV y en las Neural Network tambien es complicado extraer esa informacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0xJ5i9XMVp0"
      },
      "source": [
        "###PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WElZhMLOHHK"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZnJheBiUo7P"
      },
      "source": [
        "pca = PCA().fit(X)\n",
        "pd.DataFrame(pca.components_, columns=X.columns).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcitFOYSVHxG"
      },
      "source": [
        "per_var = np.round(pca.explained_variance_ratio_*100, decimals=5)\n",
        "labels = ['PC' + str(x) for x in range(1, len(per_var) + 1)]\n",
        "plt.plot(labels, np.cumsum(pca.explained_variance_ratio_), '-s')\n",
        "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
        "#plt.rcParams['figure.figsize'] = 5, 60\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9enNdwpXThG",
        "tags": []
      },
      "source": [
        "plt.bar(x=range(1, len(per_var) + 1), height=per_var, tick_label = labels)\n",
        "#plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu9MlDOSqExc"
      },
      "source": [
        "####Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1p21YEJpuoy"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  dt4 = DecisionTreeClassifier()\n",
        "  dt4.fit(X_new, Y1)\n",
        "  acc = dt4.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, dt4.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beE4h-4ZNhE4"
      },
      "source": [
        "####Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn17SjcRrmfZ"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  rf4 = RandomForestClassifier(40, n_jobs=-1, oob_score=True)\n",
        "  rf4.fit(X_new, Y1)\n",
        "  acc = rf4.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, rf4.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nImaIJD2Xhg"
      },
      "source": [
        "####XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cINn9Y92gvn"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  model = XGBClassifier(n_estimators=80,  max_depth=10)\n",
        "  model.fit(X_new, Y1)\n",
        "  acc = model.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, model.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK-wod5Z2eeT"
      },
      "source": [
        "####Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIxINZY32eWG"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  model = LGBMClassifier(boosting_type='gbdt',objective='binary')\n",
        "  model.fit(X_new, Y1)\n",
        "  acc = model.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, model.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZBFYDMPNlpO"
      },
      "source": [
        "####KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIDd9loXuTwL"
      },
      "source": [
        "max = 0\n",
        "components = 0\n",
        "for n in range(66):\n",
        "  pca = PCA(n_components=(n+1))\n",
        "  X_new = pca.fit_transform(X)\n",
        "  Xt_new = pca.transform(Xt)\n",
        "  knn4 = KNeighborsClassifier(4)\n",
        "  knn4.fit(X_new, Y1)\n",
        "  acc = knn4.score(Xt_new, Yt)\n",
        "  f1 = f1_score(Yt, knn4.predict(Xt_new), average='weighted')\n",
        "  print('Score usando ', (n+1), 'componentes F1:',  f1, ' acurracy: ', acc )\n",
        "  if f1 > max:\n",
        "      max = f1\n",
        "      components = n+1\n",
        "print('Mejor Score usando ', components, 'componentes F1:',  max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_DEMpQgfNrp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}